

###### 对于一个读多写少的大表，如果要增加一个字段，可以怎么做

###### 301与302的区别，303、307分别又是什么？

###### Concurrent下面有哪些包，原理是什么
ConcurrentHashMap/CopyOnWriteList/AtomicInteger

###### 网络攻击手段
XSS，CRSF

###### 事务特性（ACID）->隔离级别->InnoDB默认隔离级别可重复读->MVCC->可重复读的问题->undo log

###### MySQL如何实现主备一致

###### 进程线程，一个进程中有10个线程，一个线程挂了，其他线程会挂吗？

###### Session和Cookie

###### 索引类型
唯一索引、普通索引。唯一索引是指用unique约束的列生成的索引。普通索引就没有这个unique约束，可以有重复值。
>说到这两个索引类型，我想再提一下change buffer写缓冲机制，这是只有普通索引才支持的一种机制，用于减少磁盘IO的耗费，将对非唯一索引的写操作暂存在change buffer中，等到下一次要对这个数据页进行读操作的时候再将其加载进buffer pool，然后将change buffer中记录的操作都更新到buffer pool中对应的这个数据页内，再将读结果返回给上层应用，这个数据页会在buffer pool中暂留一段时间，到合适的时机才会被刷回磁盘。
->buffer pool是一种减少磁盘IO耗费的机制；以页的形式缓存数据，与OS一样，一个页对应机械磁盘的一个扇区（4K），这样可以提升效率；缓冲池常见的内存页管理算法是LRU，但是与OS使用的有点不同，InnoDB对其进行了优化。主要是为了解决两个问题：预读失效和

->然后刚刚有提到数据页刷回磁盘的时机，这里要涉及到redo log+binlog容灾和两阶段提交的概念。redo log是InnoDB引擎才有的一种日志机制，其中记录的是在事务执行过程中对每个数据页所做的更改。binlog是Server层的日志系统，不区分引擎，它记录的只是已执行的SQL语句的原始逻辑。
-----------------------------------------------
### 3.23
###### 比起HTTP1.1，HTTP2.0有什么改进
* Header压缩：收发双方维护一个头信息表，请求一发送所有的头部字段，对方缓存在本地后，之后的请求都只需要发送差异数据，减少冗余数据，降低开销。
* 传输方式：HTTP1.1使用pipeline的方式传输，一次可以按序发送n个请求，然后必须按序收到n条response才能继续发送之后的请求。HTTP2.0使用stream的方式传输，充分利用TCP带宽，可以连续发送很多条请求，可以乱序发乱序收，解决了HTTP1.1的队头阻塞问题。
* 编码格式：HTTP1.1发送的每条报文都是将header和body放在同一个HTTP报文中发送，并且发送的都是文本格式的信息。但是HTTP2.0会将报文信息进行二进制编码，同时会将header和body分为2个二进制帧进行分帧发送，提升效率。
* 资源推送：HTTP1.1在建立HTTP连接后，必须由一方主动发起请求，另一方才会返回其需要的数据。但是HTTP2.0会在建立连接后，由服务端主动推送客户端需要的资源，这叫做Server push。

###### QUIC
* 使用udp作为传输层的协议，在应用层实现可靠传输，解决了TCP的队头阻塞问题。
* 每个数据报都有自己单独的pack id，包括重传的包的id也是不同的，这样可以对ack进行更好的辨别，从而准确计算出rtt，更好的估算rto。
* 缓存上一次tls的秘钥信息，在下次建立连接的时候可以省去非对称加密传输和生成新对称秘钥的过程
。

### 3.21
###### redo log是怎么实现事务的
* redo buffer保存对数据库的修改，不用每次都刷新数据页，这是单独用binlog无法实现的
* redo log通过redo buffer来实现事务，在执行一个事务当中的多条语句的时候，InnoDB会将其对数据页的修改先写到redo buffer中，然后在commit的时候再写到buffer pool的真实数据页中。而对于不支持事务的MyISAM而言，每执行一条SQL语句都要直接对数据页进行修改。  
* redo log有2个作用，一是实现事务，二是将随机IO优化成顺序IO。
* redo log的两阶段提交保证的是与binlog的一致性。

###### 浏览器缓存什么时候失效
Expires、Cache-Control
>[浏览器缓存看这一篇就够了](https://www.sohu.com/a/306017942_669829)
>[【转】谈谈浏览器的缓存过期时间](https://www.cnblogs.com/yuanzai12345/p/5946730.html)

### 3.20
###### Java的引用类型有哪些？
* 强引用：我们平时使用的最多的就是强引用，直接用一个引用变量指向一个对象，比如Integer i = new Integer(0);
* 软引用：拥有软引用的对象一般不会被JVM回收，只有当堆的使用率临近阈值时，才会去回收软引用的对象。可以用SoftReference实例来保存Java对象的软引用。软引用主要用于实现类似缓存的功能，当内存空间足够的时候，可以直接通过软引用取值，无需从繁忙的真实来源查询数据。
* 弱引用：只要GC启动就会回收弱引用的对象，可以和引用队列配合使用，主要用于监控
* 虚引用
>[JAVA中的引用](https://www.cnblogs.com/czx1/p/10665327.html)

###### TCP三次握手
1. 客户端发送SYN包，CLOSED->SYN-SEND
2. 服务端发送SYN+ACK包，LISTEN->SYN-RCVD
3. 客户端发送ACK包，SYN-SEND->ESTABLISHED
4. 服务端收到ACK，SYN-RCVD->ESTABLISHED
上述过程均由OS全权处理，不经过应用层
携带信息：初始序列号、端口号、滑动窗口大小、最大消息长度等
###### TCP四次挥手
1. 客户端发送FIN包，ESTABLISHED->FIN-WAIT1
2. 服务端返回ACK包，ESTABLISHED->CLOSE-WAIT；客户端收到ACK，FIN-WAIT1->FIN-WAIT2
3. 服务端发送FIN包，CLOSE-WAIT->LAST-ACK
4. 客户端返回ACK包，FIN-WAIT2->TIME-WAIT，2MSL后进入CLOSED
5. 服务端收到ACK，LAST-ACK->CLOSED
* CLOSE-WAIT在干嘛？此期间TCP连接处于半关闭状态，主动发起断开连接的一方（这里是客户端）只能收不能发，被动要求断开连接的一方（服务端）如果是数据接收方，会让应用进程尽快拿走接收缓存中的数据，如果是数据发送方，会将发送窗口中的剩余数据发送出去。准备工作做完后，就通知客户端自己可以断开连接了。
* TIME-WAIT为什么要等待2MSL？TCP有一个报文超时重传机制，一般设置的超时时间t低于MSL（最大报文存活时间），发出报文起计时，如果超过时间t还没有收到ACK，就会重发这个报文。如果客户端返回的ACK丢失，没有被服务端收到，那么在2MSL内客户端大概率会收到服务端重传的FIN报文，然后重新返回一个ACK，仍然继续等待2MSL再进入CLOSED状态。假设客户端没有等待2MSL而是直接关闭连接，一旦这个唯一的ACK丢失，不管服务端怎么重传FIN都得不到任何回应，但是又不敢把连接断开，于是这个端口就永远无法被释放，造成端口浪费。
###### TCP和UDP的区别
1. TCP可靠，UDP不可靠
2. TCP有序，UDP无序
3. TCP面向字节流，UCP面向报文
4. TCP面向连接，UDP面向无连接
5. TCP支持流量控制和拥塞控制，UDP不支持
6. TCP仅支持一对一通信，UDP支持一对一、一对多、多对多
###### 垃圾回收机制GC，cms，G1，垃圾回收的算法
* CMS通过 **牺牲GC系统的吞吐量(单位时间执行GC的次数)** 来获得**最短回收停顿时间STW**，但是由于STW时间减少了，单位时间内响应的用户线程的请求增多了，所以整个系统的吞吐量反而增大了。
* 三色标记法：
1. 黑色：对象被标记，内部的引用也被标记完毕
2. 灰色：对象被标记，但是内部的引用没有被标记
3. 对象未被标记
* CMS/G1如何降低GC带来的系统响应延迟？
* CMS碎片整理；G1控制GC时间，计算Region回收效率，优先队列。

### 3.18
###### 说一说C++的动态内存分配（new）
C++中，所有内存需求都是在程序执行之前确定的，但是存在某些情况需要在运行时才能确定确定内存需求的情况，比如需要的内存取决于用户的输入，这种情况下就需要动态分配内存。C++中new是和delete配合使用。

###### new和malloc的区别
new是C++的库哈数，malloc是C的库函数
new是以具体类型为单位分配内存空间，malloc是以字节为单位来分配内存
new在申请单个类型变量时可以进行初始化，malloc不行

###### const的作用，加不加const有什么区别
修饰一个常量，限制其只可读，不可写

###### 构造函数可以是虚函数嘛，为什么？
从存储空间角度
虚函数对应一个vtable，可是这个vtable其实是存储在对象的内存空间的。
那么问题来了，如果构造函数是虚函数，就要通过vtable来调用，可是对象空间还没有实例化，也就是内存空间还没有，无法找到vtable，所以构造函数不能是虚函数。

从使用角度
虚函数主要用于在信息不全的情况下，能够使重载的函数得到对应的调用。构造函数本身就是要初始化实例，那使用虚函数也没有实际意义。
另外，虚函数的作用在于通过父类的指针或者引用来调用它的时候能够变成调用子类的那个成员函数，从而实现多态，也就是实现“一个接口，多种方法”。而构造函数是在创建对象时自动调用的，不可能通过父类的指针或者引用去调用，因此规定构造函数不能是虚函数。

###### sizeof和strlen的差别
Sizeof是运算符，在编译时期就确定了返回值。Strlen是函数，在运行时才会返回结果。
Sizeof是用来计算变量、数组或者某个类型、对象所占的内存空间大小，返回的是字节数。Strlen用于统计字符串的长度，传入的是字符数组名或字符指针，统计到’/0’为止，不包括’/0’。

###### 说一说#if
\#if与#endif搭配使用，叫条件编译指令。根据宏条件选择性地编译语句

###### 有几千亿条数据（词语），统计一下其中出现频率最高的前100个词语
将数据分成多个小文件，统计每个小文件中出现频率排在前100的数据，然后进行归并，再分文件统计、再归并，直至剩下最后100个数据。
>[教你如何迅速秒杀掉：99%的海量数据处理面试题](https://www.jianshu.com/p/e8b9e034e100)

### 3.17
###### TCP的糊涂窗口综合征
* 如果发送方的应用进程发送数据速率太慢，或者接收方的应用进程读取数据的速率太慢，都会引起糊涂窗口综合征，他们都有各自的解决方案。
* 首先说下发送方引起的，如果发送方的应用进程发送数据的速度比较慢，每次都只给一个字节，那么TCP每次都只会打包一个字节的数据，然后经过层层包装发送出去，IP头占20字节，TCP头占20字节，那么一个IP数据包就是41字节，真正的数据只有1字节，这将导致网络流量的利用率十分低下。可以用nagle算法解决发送方的问题。nagle算法要求TCP连接中只能有一个发送未确认的小分组，其他小分组必须等这个小分组被确认后才可以发出去。因此发送方在发送了一个小分组后，会等待一段时间，这段时间应用进程发送的小分组会不断积累成一个大分组，最终在达到MSS时发出。
* 接收方也会引起糊涂窗口综合征。原因是应用进程读取数据的速度比较慢，导致接收缓冲很快就满了，每次应用进程都只读取一个字节的数据，然后接收方就发送一个rwnd=1的确认报文，发送方每次就只能发一个字节过来，然后缓冲区又满了，接收方就又得返回一个rwnd=0的报文让发送方停止发送。clark算法可以解决这个问题，如果接受缓冲剩余空间不足一半，每次收到数据都返回一个零窗口报文，直至接收缓冲空出了一半的空间就返回一个正常的确认报文，让发送方开始发送数据。
>#### [37-tcp协议——糊涂窗口综合征和nagle算法](https://blog.csdn.net/qq_35733751/article/details/80224079?tdsourcetag=s_pcqq_aiomsg)
>#### [38-tcp协议——由接收方引发的糊涂窗口](https://blog.csdn.net/qq_35733751/article/details/80231172)

###### 口述下基排的思想
* 假设要对整型数组arr进行非降序排序，先获取数组中的最大值max，然后按十进制计算max位数count（比如200的位数是3）
* 创建一个大小为10的桶数组buckets，然后再对arr进行count次遍历
* 第一次提取个位数，如果是0，push到buckets[0]这个桶中，如果是2，就push到buckets[2]，以此类推。这一轮遍历完后，所有的数据都加入到了桶数组，然后我们开始对桶数组进行遍历，从buckets[0]开始，将数据一一取出按照从前往后的顺序放入arr（注意这会覆盖arr之前的数据），接着buckets[1]、buckets[2]...这样子。
* 对桶数组的第一次遍历结束后，开始第二轮的筛选，将buckets清空，这次提取arr数据的十分位，一一放入对应的桶中，然后再按序放回arr。
* 如此往复，直至count次遍历结束。此时arr已是一个有序数组。

###### DNS原理？
当我们在浏览器输入一个URL并回车的时候，就会发生DNS，即域名解析，将URL映射到一个IP地址，拿到IP地址后才能发送HTTP/HTTPS请求。首先会查询浏览器的缓存，如果没有，就去本地hosts和DNS缓存中查找，如果依旧没有，就去路由器的缓存中找，还是没有的话，就将请求发送给ISP DNS服务器，首先也是去本地缓存找，没有的话就只能向根域名服务器发送DNS请求，根域名服务器收到后会返回对应的顶级域名服务器的IP地址，本地DNS服务器再发请求给顶级域名服务器，顶级域名服务器会返回权威域名服务器的IP地址，本地DNS服务器接着去权威域名服务器找，如果权威域名服务器找到了这个URL对应的IP，就返回给本地DNS服务器。
这时DNS服务器将这个URL到IP地址的映射放入自己的缓存中，然后返回给路由器，路由器存入缓存后发给主机，主机存在DNS缓存中再交给浏览器，这时浏览器拿到了这个IP地址后，就可以发送真正的HTTP请求了。
>#### [Linux系统下搭建DNS服务器——DNS原理总结](https://zhuanlan.zhihu.com/p/31568450)

###### InnoDB为什么要多加一个redo log？有binlog恢复数据不就够了吗？
binlog+redo log是实现事务的机制，只有binlog的MyISAM不支持事务，因此每次都会将数据页的更改持久化到磁盘，但是这个过程通常是随机IO，磁头要不断地大范围移动，寻找目标盘面和扇区，耗费较大。但是InnoDB的redo log在磁盘的位置都是连续的，其持久化过程是顺序IO，每次磁头仅需移动1个扇区，因此效率较高。binlog+redo log容灾机制就能够避免频繁将数据页刷回磁盘，同时由于有redo log和binlog的日志记录，即使意外宕机，数据没来得及刷回磁盘，但是因为redo log和binlog每次事务提交的时候都会持久化到磁盘，因此可以通过这两个日志记录来恢复数据。这就是InnoDB的WAL机制。另外，redo log的两阶段提交机制可以尽量避免与binlog不一致的情况。

### 3.16
###### spring的工厂模式
* spring通过BeanFactory这个工厂来管理Bean。
* BeanFactory本身是一个接口，ApplicationContext是对这个接口的实现，它首先需要读取xml配置文件，在这个配置文件中声明了很多个Bean，这些Bean就是需要创建的对象，全部由BeanFactory管理。
* Bean从生命周期上可以划分为Singleton和Prototype。Singleton在spring开始运行的时候就会被创建，Prototype只有在调用getBean的时候才会被创建，并且每次调用都会创建新的对象。
* Bean从用途上可以划分为普通Bean和FactoryBean。如果是普通Bean，通过getBean返回的就是这个对象，如果是FactoryBean，返回的就不是这个FactoryBean对象了，而是工厂Bean代理创建的实例对象。
* 这里说到了BeanFactory和FactoryBean，名字看上去挺像的，但是这两者完全不是一个概念。BeanFactory是一个容器，用于管理xml配置文件下的所有Bean；而FactoryBean只是一个特殊的Bean，只是在getBean的时候返回的不是本身，而是代理创建的实例对象，它也是由BeanFactory管理的。

###### 僵尸进程是什么
* 僵尸进程：当一个子进程运行完毕退出之后，其进程描述符依旧存在，只有父进程调用wait或waitpid才会释放子进程的描述符。如果父进程一直没有调用wait，子进程的进程号就无法被释放，成为僵尸进程。通过Linux shell命令ps可以看到僵尸进程的状态是Z，表示zombie。如果存在大量僵尸进程，将导致无法分配新的进程ID，即无法产生新进程。要消灭僵尸进程，只需将父进程杀死，让僵尸进程变为孤儿进程，被init收养后由init释放它占有的资源，从而结束掉僵尸进程。
* 孤儿进程：当父进程退出后，如果子进程还在执行或者已退出但是父进程没有wait它，那么这个子进程就会成为孤儿进程，被进程号为1的init进程收养。
* 守护进程：运行在后台的一种特殊进程。一般是随系统启动而产生的非交互式进程，除非强行终止，否则会一直运行到系统关机。
* 后台进程：

###### 数据库设计表的三大范式
3+1范式
1. 第一范式：列不可再分
2. 第二范式：非主键必须依赖主键的全部列而不是部分列
3. 第三范式：主键A必须能够同时确定非主键B和非主键C，而不能是非主键B依赖主键A，C依赖B
4. BC范式：候选键之间必须是完全依赖，而不能是部分依赖

###### 你是怎么理解同步和异步的？
同步和异步是针对执行计划而言的。同步是严格按照执行计划的顺序执行下来，中途有可能为了同步其他线程而被阻塞或者轮询等待，即同步阻塞和同步非阻塞，比如父线程join一个子线程，父线程必须等到子线程返回才能继续执行，这叫同步。异步是指两个线程按照自己的执行计划进行，互不干扰，不会被阻塞，即异步非阻塞，比如父线程fork一个子线程后，可以继续执行接下来的执行计划，不知道也不用管子线程现在会执行到哪。

IO复用是异步还是同步？
IO复用是同步非阻塞的，由一个线程管理多个Socket通道，通过对Socket进行轮询来查看是否有IO通道发出IO请求，因此所有的IO请求都是同步进行，一次只能有一个Socket通道的IO请求被线程处理，其他通道的IO请求将在之后的轮询中被响应。
>IO复用->select、poll、epoll及三者的区别

### 3.15
###### Python的协程
假设有一个单线程和2个function A和B，A执行到一半，调用了B，此时有2个选择，一种是先执行B，另一种是继续执行A的后一半，这两种就是2个协程。

###### 口述下桶排的思想
桶排是对计数排序的一个改进，减少大数据下的大内存占用。
假设要对一个整型数组arr[10000]进行排序，首先遍历数组找出最小值min和最大值max，得到差值err，表示这个范围内的整数个数，如果是计数排序，就会创建一个大小为err的计数数组，然后再次遍历arr进行计数。
但是桶排序会先将err分成多个桶。假设min为0，max为10000，分为100个桶，那么每个桶的大小是100，比如第一个桶放的是数值在[0,100)内的数据，第二个放的是[100,200)的数据，以此类推，一共100个桶。确定好桶的大小后，再次遍历arr，判断元素位于哪个区间，然后加到对应的桶中。遍历完后，对100个桶分别进行排序，然后从第一个桶开始按序取出其中的数据放入arr，就是一个排好序的数组。
假设使用的是插入排序，只要每个桶中的数据足够少，就能说对k个桶排序的时间复杂度为O(k)。由于前面都是数组遍历操作，其时间复杂度为O(n)，总的时间复杂度就是O(n+k)，空间复杂度也是O(n+k)。

###### TCP拥塞控制？MSS是什么？有什么作用？
* 拥塞控制机制的目的是为了解决网络拥塞的问题，在网络十分拥塞的情况下，发出的数据报很有可能丢失，如果此时不断重传，只会增加网络堵塞的程度，因此需要一个机制来避免给网络添堵。
* 在讲拥塞控制之前，需要先讲一下滑动窗口和缓冲区图的概念。接收方的接收缓冲区分为3部分，接收已ACK、可接收未ACK、不可接收，通告窗口就是允许接收的数据。发送方的发送缓冲区分4部分，已发送已ACK，已发送未ACK，未发送但可以发送，未发送且不能发送，其发送窗口涵盖了中间2部分的数据。发送窗口也叫做拥塞窗口cwnd，会随着网络拥塞状态进行大小的调整，这就是拥塞控制。  
* 拥塞控制有4种算法，慢开始、拥塞避免、快重传和快恢复。  
* 慢开始的cwnd初始为1，表示一次最多只能发送一个字节，之后每次发送前都会将cwnd增大到之前的2倍，直至ssthresh，也就是慢开始门限，然后转为拥塞避免算法。  
* 此阶段cwnd从ssthresh开始，每次发送前都将cwnd加一，呈线性增长，虽然cwnd可以无限增长，但并不意味着可以一次性发送无限个字节数。发送方一次可发送的最大字节数是受window_size限制的，window_size取的是min(cwnd,rwnd,mss)。  
* 如果接收方接收到了1、2、4、5这几个字节，那么接收方只会对连续字节的最后一个2进行确认，如果仍然没有收到3这个字节，就会连续发送3个相同的ACK包，告知发送方3这个字节丢失了，发送方收到3个相同的ACK包后，就快重传3这个字节，然后进入快恢复阶段。  
* 快恢复阶段会将ssthresh变为当前cwnd的一半，再将cwnd降到ssthresh，此时直接进入拥塞避免。  
* 再讲讲MSS，这是最大报文段长度，在TCP三次握手阶段会交换的一个信息之一，用于告知对方自己这边可以接收的最大TCP报文段长度。这个值是可以自己设定的，一般设为路径上的最小MTU减去IP头和TCP头的长度。比如MTU一般为1500，那么MSS就可以设为1500-20-20=1460。这样设置可以避免在传输过程中被路径上的路由器再次分片，拉低传输效率。

###### synchronized的升级机制
1. 首先要说下对象在内存中的存储。堆中的对象由对象头、实例数据、对齐填充3部分组成。  
2. 对象头又包含2部分，第1部分用于存储运行时对象的自身数据，叫做markword，包含了hashCode、偏向时间戳、GC分代年龄、锁标志位、偏向线程ID、指向栈中锁记录的指针、指向Monitor重量级锁的指针等信息。第2部分是指向类元数据的指针，虚拟机运行时通过这个指针来得知这个对象属于哪个类。  
3. synchronized的升级机制与对象头中的markword密切相关。markword在32/64位虚拟机中分别占用32/64位的空间，我以32位为例。这个32个bit可以分时表示5种不同的状态，用1bit的偏向锁标志位与2bit的锁状态位表示，010表示无锁，110表示偏向锁，000表示轻量锁，001表示重量锁，011表示GC。synchronized的升级机制涉及到的是前4个状态，从前到后逐层升级。
4. synchronized的具体升级过程
* 对象头的markword初始是无锁状态
* 第一个线程T1到达同步区，检查markword，发现是无锁状态，于是将其升级为偏向锁，同时用CAS将偏向线程ID变成自己的ID
* 第二个线程T2到达同步区，检查markword，发现是偏向锁，然后再检查偏向线程ID是否是自己的，发现不是，于是让JVM去检查T1的状态，
	* 如果T1没有在运行或者已经退出同步区，就将偏向锁降级为无锁，然后T2将偏向线程ID替换成自己的，同样也是用上一步的CAS操作。
	* 如果T1仍在运行且仍在同步区内，等待T1运行到安全点，再暂停T1。此时JVM将偏向锁升级为轻量锁。
* 升级轻量锁后，markword变为匿名状态，即32位全0，JVM在T1栈帧中生成一个锁记录，将匿名markword拷贝到该锁记录中，令markword中的指针指向T1的锁记录，最后唤醒T1线程。
* T2不停将当前对象头markword与匿名markword比较
	* T1没有退出同步区，T2将一直比较失败
	* T1退出同步区，释放了轻量锁，markword恢复匿名状态，此时T2比较成功，进入下一环节。
* JVM在T2栈帧中生成一个锁记录，拷贝匿名markword进去，并用与前面T1同样的CAS操作将当前对象头的markword的指针替换成T2的锁记录的首地址，假设此时T3也比较成功了，并且抢先一步替换成功，T2的CAS失败，于是JVM将轻量锁升级为重量锁。
* 升级为重量锁后，markword的最后两位为01，前30位指向对象实例数据中的Monitor对象，Monitor底层是使用OS的mutex lock对线程进行过阻塞，因此T2就被阻塞并放入对象的锁池中，等待被唤醒。

>[synchronized关键字详解及分析锁升级过程](https://blog.csdn.net/baidu_38083619/article/details/82527461)

### 3.14
###### 了解过ThreadLocal吗？原理是什么
ThreadLocal用于隔离线程，保证各个线程都拥有自己私有的变量副本，互不干扰。这些变量一般是和线程绑定的状态信息，如用户ID、事务ID等。  
每个Thread对象都拥有一个实例变量threadLocals，其中存放了属于这个线程的所有ThreadLocal变量，可以通过调用ThreadLocal对象的set、get方法访问到对应的value，initValue会返回线程本地变量初始值，remove将移除对应的ThreadLocal变量。  
事实上，ThreadLocal本身不存储值，真正起作用的是ThreadLocal的静态内部类ThreadLocalMap，上面提到的threadLocals其实就是ThreadLocalMap类型的实例，其中放了很多个Entry，即K-V键值对，ThreadLocal对象只是作为key，用于映射map中的value，这才是真正存储值的地方。  
总结来说，每个Thread对象中有一个ThreadLocalMap对象的引用，叫做threadLocals，threadLocals中放了很多K-V键值对，key是ThreadLocal对象的引用，value是专属于这个线程的本地变量，也是对象引用，可以是Integer，也可以是String等。不同的线程可以共用同一个ThreadLocal对象，即用相同的key，但是因为map是线程独有的，其映射的value一定不会是同一个对象引用，从而实现了多线程间变量的隔离问题。  
与多线程同步不同，多线程同步解决的是多线程操作同一个共享变量的问题，而ThreadLocal解决的是线程本地变量隔离的问题，保证一个线程只能操作自己的本地变量，不会干扰到其他线程的本地变量。  
但是ThreadLocal有一个内存泄漏的风险。从源码中可以看到Entry中key的引用是弱引用，这对GC回收是有利的，但是又因为value是强引用，因此就会出现key被GC变为null，而value仍保留着强引用的情况，此时value不再被使用，但却一直被Thread对象间接强引用着，导致其内存一直无法被释放，除非Thread对象被清理掉。为了解决这个问题，ThreadLocalMap中的setEntry和getEntry中有这样一个判断，如果刚好找到一个key==null的Entry，就会将对应的value置为null，当然我们也可以显式调用ThreadLocal的remove方法进行处理。

>[【死磕Java并发】—–深入分析ThreadLocal](http://cmsblogs.com/?p=2442)

###### 网络层协议
有IP和ICMP。IP协议是用于规范网络层的格式，确保有源IP地址和目的IP地址，声明数据报的长度，以及上层协议。如果使用了ICMP，那么IP头中的协议字段就是ICMP，但这并不意味着ICMP是传输层的协议，因为ICMP报文中并没有端口号字段，它只是一个网络层协议。
ICMP有两种应用，分别是ping和Traceroute。ping是用到的是ICMP查询报文，用于探测某个IP是否存在以及能否响应。Traceroute使用的是差错报文，它有2大作用：一是用来追踪一个数据报发送过程途径的所有路由器，这是通过设置特殊的TTL值来实现的，一开始TTL是1，之后依次是2,3,4...，从而获取到每一跳的IP地址。当TTL减为0时，最后一个收到这个报文的的路由器就会向源主机返回一个超时差错报文，这样就可以拿到该路由器的IP地址。第二个作用是确定这条路径的最小MTU（允许通过的最大报文长度），这需要设置不分片位，让路由器返回终点不可达差错报文。

###### JVM内存分区
方法区（非堆）、程序计数器PC、虚拟机栈、堆区、本地方法栈
方法区用于存放加载进来的类信息以及所有的方法代码，在程序运行过程中PC会指向方法区中要执行的下一条指令。
每个线程都有一个虚拟机栈，当执行到某个方法时，会将该方法的栈帧入栈，栈帧中包含了操作数栈、局部变量表、出口地址等。局部变量表中的基本类型数据是私有的，但是对象引用指向的堆中的对象是共享的。
堆区一般比较大，是用于存放对象的，由于对象都有一定的存活时间，随时都会产生一些不再需要的垃圾对象，因此对应的就有一些GC垃圾回收机制。
本地方法栈是用于存放本地方法的，如果线程执行到一个native方法，就会将这个方法对应的栈帧入栈，与虚拟机栈类似，只不过面向的是本地方法。本地方法一般的C编写的程序。

### 3.13
###### 听过冲突域吗？交换机和集线器的冲突域分别是什么？
冲突域就是可能发生冲突的最小单位。交换机的冲突域是单个接口，集线器是所有接口。因为交换机一次只会往一个接口发送数据，而集线器每次都是广播。

###### Object类里面有哪些方法？解释一下几个重点方法
重要的方法有getClass/hashCode/equals/clone/notify和wait/finalize
* getClass是获取对应类的Class对象，通过这个对象可以获取类元数据和类信息的入口
* hashCode用于获取对象的哈希值，如果不重写，默认是用对象的基址来计算，意味着同一个类的2个不同对象的hashCode是不同的，这个hashCode会存在对象头中。
* equals是非本地方法，不重写的话默认是和传入的对象引用直接进行基址的比较，也可以重写自定义比较规则。
* clone用于克隆对象，在另一块堆内存中创建一个相同的对象，包括其中的变量引用等，都是直接复制相应的值，属于浅拷贝。
* notify和wait要配合使用，与对象的锁池和等待池有关，通常与synchronized一起使用。synchronized是一个关键字，用于修饰方法或者代码块，表示这段代码加了独占锁，同一时刻只能有一个线程拿到对象的Monitor并执行，其他想要拿锁的线程都将被阻塞并放在对象的锁池中，一般用于需要同步线程的场景下。在synchronized修饰的代码块中，可以通过调用对象的wait方法去阻塞已经进来的线程，wait会将对应线程加入对象的等待池，并释放Monitor锁，唤醒锁池中的下一个线程。notify是用于唤醒等待池中的第一个线程，然后再放入锁池中，再次进入阻塞，等待Monitor锁被释放。相应的还有一个notifyAll，与notify类似，唯一的区别在于notifyAll是唤醒等待池中的所有线程。
* finalize在Object中默认什么都不做，这个函数在对象要被GC回收的时候会自动触发，如果我们希望在回收这个对象之前做一些逻辑处理，就需要重写finalize方法。
>[从JDK源码角度看Object](http://cmsblogs.com/?p=5200&tdsourcetag=s_pcqq_aiomsg)

### 3.12
###### 1000w条个int型数据，找出其中前5大的，怎么找？
维护一个大小为5的小顶堆，将剩下的数据一个一个取出来与堆顶比较，比堆顶小或者相等就直接抛弃，否则替换堆顶，同时调整堆。不断重复直至全部数据都已经比较完毕，剩下的堆中的5个元素就是最大的5个。

###### 1000w条数据，每一个数据的范围为（0，5000），怎么样排序
用一个大小为5000的整型数组计数，时间复杂度为O(n)。

###### 1000w条数据，每一个数据的范围是(0, Integer.MAX_VALUE)，如何排序
由于内存有限，在不考虑磁盘I/O开销的前提下，可以创建多个大小为5000的数组文件放在磁盘中，分别记录范围(0,5000),(5001,10000),...的数据个数。在遍历1000w条数据的时候判断其大小落在哪个区间，然后加载对应的文件进行计数。

###### 首先有一个时间序列，从0000到21w，每个人有一个上线时间和下线时间，然后有很多个人，请问怎么找出在线人数最多的时间段（每天从0秒到24*60*60秒）
使用差分法。创建一个大小为24*60*60的数组Time[]，表示时间轴。如果有一个人在x秒上线、y秒下线，就令Time[x]++，Time[y]--。一天结束了，要进行统计时，就令Time[i]+=Time[i-1]。这个数组就表示每秒钟的在线人数。

###### 子类和父类的实例变量和方法有什么区别
* 实例变量是归对象所有，每个对象都有自己单独的实例变量，子类和父类也是一样，子类只是继承了父类的属性，只要创建了新的子类对象，就会在堆中单独开辟出新的内存空间用于存放这些实例变量，与父类无关。父类的实例对象也会有自己独立的实例变量。
* 方法代码都存放在非堆中，子类继承父类，意味着子类可以调用父类的方法，具体调用过程由JVM去操作，对用户是透明的，因此我们感觉就是子类复制了父类的方法代码一样，实则不然，他们实际执行的都是同一块内存中的方法代码。
* 只有当子类重写了父类的方法或者添加的自己的方法时，才会在子类所在内存空间中增加新的方法代码。如果是动态方法，会去方法区中查询对应类的方法表，其中存放了所有动态方法的符号引用到直接引用的映射，包括所有父类的方法和自己独有的方法，其中重写的方法会映射到子类所在内存空间中的方法入口地址。这是实现运行时多态的基础。

###### map和unordered_map有什么区别？红黑树有什么特点？
* map是用红黑树实现的，插入和删除都会进行调整，保证始终是排好序的，插入删除查询的时间复杂度都是O(logn)；unordered_map用哈希实现，是无序的，尽管插入删除查询时间复杂度为O(1)，但是不利于范围查找。
* 红黑树的根节点和所有叶子节点是黑的，叶子节点是空节点。红节点的父节点和孩子节点都是黑的。从任一节点出发到每个叶子节点的简单路径都包含了相同的黑色节点。红黑树本质也是搜索二叉树，是介于平衡二叉树和普通二叉树的一个折中设计，要求左子树高度最多不超过右子树的两倍或者不少于右子树高度的一半，维护开销比平衡二叉树小，查询效率比普通二叉树高。

###### java泛型
* Java的泛型类似于C++的模板template，用诸如<E>这样的形式表示。用在集合中是为了兼容所有的类型，同时也是为了统一集合中的引用数据类型。比如ArrayList，底层是用数组实现，数组中存放的都是某种数据类型的引用，具体是哪种数据类型需要在创建对象的时候才能确定，比如ArrayList<Integer> arr = new ArrayList<Integer>();就表明这个集合中的元素都必须是Integer的引用。
* 泛型可以是任意一个符号，比如MyClass<E>，E就是一个泛型，可以用E去定义泛型引用，也可以作为方法的参数类型和返回值类型。
* 泛型可以延伸出泛型方法、泛型类、泛型接口三大应用。泛型方法的参数必须有泛型，其返回值可以是泛型，在调用方法传参的时候才能确定泛型的具体类型。泛型类是指在定义类的时候声明泛型，比如ArrayList<E>等JDK集合类都是泛型类。泛型接口是在定义接口的时候声明泛型，实现类可以直接指定泛型的类型，也可以不指定，但是也要声明泛型。
* 泛型还有一个概念是泛型上限和泛型下限。List<? extends B>表示后面的<>只能传入B或B的子类，这叫泛型上限；List<? super B>表示后面的<>只能传入B或B的父类，这叫泛型下限。泛型上限只能用于获取某些对象的值，不能调用其中需要传递泛型参数的方法，比如add()。泛型下限则可以，但是传递的泛型只能是B/B的子类。
>[java泛型理解和深入](https://zhuanlan.zhihu.com/p/40925435)

### 3.11
###### 如何查询比较高效
查询时尽量利用索引覆盖，而且不要做会导致索引失效的查询操作
	1. 查询时尽量使用最佳左前缀，即查询条件如果有多条，其条件检查的顺序要按照索引树的搜索顺序排列；
	2. 尽量不要使用通配符在前的like模糊匹配；
	3. 字符串一定要加上引号，否则会退化成普通查询，进行全表遍历。
	4. 尽量不要在条件中使用聚集函数。

###### 口述一下快排的思想
假设要将数组buf排列成非递减序列。
1. 首先，在数组中选取一个哨兵guard，比如buf[mid]
2. 用左右两个指针left,right指向数组的两端
3. left指针从左往右扫描，直至第一个不小于guard的元素为止，然后right从右往左扫描，直至第一个不大于guard的元素为止
4. 交换left和right指向的数组元素值
5. 如果left和right没有相遇，继续重复执行上述扫描操作；如果相遇，以right为分界线，将数组分为两段，分别用同样的方法递归处理这两段，递归出口是要处理的数组段不可再分。

### 3.8
###### 发生exception的时候是怎么进行try catch finally的？底层原理是怎么实现跳转的
在反编译字节码中可以看到有一个Exception Table字段，其中包含了exception的类型，from、to、target字段，如果从from到to的代码执行过程发生异常，就会跳转到target处处理异常。

###### 你有接触过设计模式吗？有听过哪些设计模式？单例模式是怎么实现的？
* 有单例、工厂、观察者等设计模式。
* 单例模式是指一个类只能有一个实例，并提供全局访问点。
* 单例模式是通过一个私有构造函数、一个私有静态变量、一个公有静态方法来实现的。私有构造函数是为了防止外界通过直接调用构造函数来创建实例对象，限制其只能通过调用公有静态方法返回唯一的私有静态变量，即单例。
* 单例模式有很多种实现方式：
1. 懒汉式-线程不安全  
不加锁，私有静态变量初始化为空。在公共静态方法中判断私有静态变量是否空，如果空，new一个新对象给它然后返回，如果不空，直接返回。  
很明显，在多线程并发的场景下，很有可能会有多个线程重复给私有静态变量赋新值，出现线程不安全的问题。
2. 饿汉式-线程安全  
不加锁，但是在类加载的时候就实例化，即初始化私有静态变量，之后调用公有静态方法时直接返回即可。
利用了类加载的线程安全机制，缺点是提前占用了内存资源，在有些时候是不必要的浪费。
3. 懒汉式-线程安全  
与<懒汉式-线程不安全>的区别在于，给公有静态方法加上了独占锁，用了synchronized修饰。  
虽然安全，但是可能会导致大量线程被阻塞在这个公有静态方法上，内核用户态切换频繁，导致效率下降。
4. 双重校验锁-线程安全  
在公有静态方法中的判空语句中再嵌套一个判空语句，并在第二个判空语句前加上独占锁。与<懒汉式-线程安全>相比，这种实现方式可以一定程度上降低线程阻塞概率，效率更高。
5. 静态内部类  
将私有静态变量定义及其实例化语句放在静态内部类中，只有当外部类调用内部类的这个变量时，内部类才会被加载进内存，在类加载的时候实例化语句才会执行。  
这也是利用了类加载的线程安全机制，与饿汉式不同的是，此方法只会在需要的时候才会加载类并实例化，节省内存资源，同时又实现了线程安全。
6. 枚举实现  
定义enum枚举类，其中定义一个枚举成员INSTANCE，默认为公有静态常量，并在类加载的时候被实例化，与饿汉式类似，只不过换了种定义方式。要使用该单例的时候直接用枚举类名.INSTANCE即可。
7. 乐观锁实现
在<懒汉式-线程不安全>的基础上，用CAS乐观锁的方式对公有静态变量进行赋值，保证所有竞争线程中只有一个能成功给该变量赋值，从而实现线程安全的单例。

###### 你了解http吗?http1.0 1.1有什么改进？
* HTTP是一种应用层的协议，用于规范传输应用信息的格式，便于网络信息交互。HTTP报文一般分为请求报文和响应报文。
  * 请求报文一般是客户端向服务端发送的，通过声明方法来确定该请求报文的目的，如GET就是向服务端请求数据，比如请求HTML文件用于呈现网页；POST会在服务端新增对象数据，比如用户在浏览器填写的表单字段；PUT是修改服务器的对象数据；DELETE是删除服务端的对象数据；HEAD是获取报文首部，一般用于检验URL是否有效；Connect是请求建立SSL/TLS安全连接（隧道）。
  * 响应报文是服务端返回给客户端的信息，状态码标明请求的结果状态，如200表示请求成功，一切正常，浏览器可以从实体中拿到需要的HTML/JSON文件；301表示永久性重定向；302表示临时性重定向；304表示该页面目前没有更新，无需返回新的数据；401表示客户端请求需要认证；403表示客户端请求被拒；404表示请求的页面找不到；500表示服务端正在执行请求时发生错误；503表示服务端超负荷或者正在停机维护。
* 相对于HTTP1.0，HTTP1.1做了部分改进。
  1. 引入Cookie：HTTP是无状态的，用于处理大量事务，但是有时候我们往往需要保存一些状态信息以免频繁去请求，因此HTTP1.1引入了Cookie来保存状态信息。Cookie存放在浏览器中，在每次向服务端发送请求时都会携带上Cookie信息，方便验证用户身份与更新状态。
  2. 默认长连接和流水线：HTTP1.0是默认短连接的，意味着浏览器的每次请求都要建立一个TCP连接，而这样一次TCP连接很少能通过slow-start区，不利于提高带宽利用率。因此在HTTP1.1中就改为了默认长连接，在一个TCP连接上可以发送多个请求和响应，减少连接建立和关闭的延迟与消耗。与此同时还增加了流水线机制，客户端不用等待上一个响应返回就可以直接发送下一个请求，极大地提升了下载速度，但是服务器返回的响应还是要按照顺序来，以便客户端能够区分出每条请求的响应内容，因此会导致服务器的队头阻塞问题。
	3. 引入了更多缓存控制策略，如Etag、If-Unmodified-Since等可供选择的缓存头来控制缓存策略。
>[HTTP1.0、HTTP1.1 和 HTTP2.0 的区别](https://www.cnblogs.com/heluan/p/8620312.html)

### 3.7
###### 你有用过java的反射吗?java的反射可以拿来干什么？
* Java反射是通过调用Field/Method对象的API，来访问对象中的对应字段或方法。
* 这种反射通过调用Class对象的API实现的，而Class对象可以通过类名Object.class或者对象名object.getClass()获取。Class对象不是我们自己创建的，而是在.class加载进内存时由JVM虚拟机自动创建的，包含了一系列用于访问类元信息的API。比如class.getDeclaredField("字段名")可以获取A类中某个字段的Field，实则是该字段相对于类/对象首地址的偏移量。而class.getDeclaredMethod("方法名")可以获取Method对象。
* 如果该字段或者方法是私有或者保护成员，可以先调用Field/Method对象的setAccessible(true)方法设置访问权限，然后再通过Field/Method对象的get进行访问。如果一个对象的私有/保护字段没有set/get方法，而我们要去访问这些成员时，就要通过反射的方式进行读取/修改。
* Java的反射在一些框架中有所使用，比如spring的依赖注入。Spring用到的是IoC容器，即控制反转，就是将创建对象的控制权反转给spring，由spring去替我们去创建对象然后返回给我们使用，同时控制对象的生命周期，我们只需要配置xml文件声明我们需要的对象即可。此时就需要Spring来替我们进行对象中各个字段的注入。然后往往我们自己写的类，有时候会缺少一些get/set方法，这样Spring就无法替我们进行字段的注入，因此反射机制就显得尤为重要了。

### 3.4
###### mysql中什么时候索引会失效？
1. 没有使用最佳左前缀，会导致索引部分失效
2. 使用了通配符在前的like模糊查询
3. 字符串没有加引号  
2和3都会导致全表遍历查询。

###### tcp和udp有什么区别？
1. TCP支持可靠交付，保证送达；UDP只是尽最大可能交付，不保证送达
2. TCP面向连接，只能一对一通信；UDP不面向连接，支持一对一、一对多、多对多通信。
3. TCP有流量控制和拥塞控制，有效减少丢包和减轻网络拥塞；UDP只会一股脑地把报文发出去，不管对方接不接收得过来，也不管网络是否通畅。
4. TCP面向字节流，每个字节都有自己的序列号，保证数据报的有序性；UDP面向报文，接收和发送都是无序的。
5. TCP的传输过程安全可靠但是效率低，适用于追求绝对完整和安全的场景，如支付；UDP的传输简单高效，适用于追求实时性而不过度追求完整性的场景，如直播。
>拓展
TCP长连接与HTTP长连接

### 3.3
###### 如果一个sql查询太久了，有哪些可能的原因？
1. 连接故障：客户端与服务端之间的连接出现问题，发送的查询请求迟迟没有被服务端收到，或者服务端对应进程被阻塞/死锁。
2. 数据量大：sql查询基于非索引，因此需要遍历整张表来查询。同时数据量很大，遍历时间成线性增长，故需要查询很久。
3. 阻塞：表或者对应行被其他线程锁住，然后其他线程还迟迟没有commit，导致查询无法进行下去。
4. 使用了一致性读：在要执行sql查询的事务A开始后，事务B对要查询的记录执行了大量更新操作，产生了大量undo log，之后A才开始执行sql查询，于是需要读取这期间事务B写入的所有undo log，一步一步回到事务A开始执行的状态，从而得到一致性状态下的数据并返回。

###### 什么时候需要加索引？
* 经常要用到某字段进行查找时，需要基于该字段建立索引。我们平时经常用的一般是B+树实现的索引，如果索引值频繁被修改，就需要花费大量时间来维护这棵索引树，因此用一般是用读多写少的字段建立索引树。
* 索引可被分为唯一索引和普通索引。
* 如果需要确保业务更新操作过程中，表的某个索引不能出现重复值，就要使用唯一索引。否则，一般都建议使用普通索引+change buffer缓存机制。
* 在写多读少的场景下，需要进行频繁的磁盘IO操作，内存中的内存页要不断地更新，极大地影响效率和内存利用率。change buffer机制可以解决这种问题。
  * 如果一条SQL更新语句中要写的数据页不在内存中，会先将其更新操作存在内存中的change buffer中。待下一次对该数据页执行读操作时，再读出change buffer中关于该数据页的所有记录，对该数据页进行统一修改后再返回结果，这个过程叫做merge。
  * 这种机制可以极大地减少磁盘读的IO耗费，提高SQL语句的执行效率，同时节省内存占用。
* 在读多写少的场景下，很有可能出现每次在执行完一条写操作后立马就要对这个数据页执行读操作的情况，此时change buffer机制几乎无法再降低磁盘IO的次数，同时还要增加change buffer的维护成本，此时建议关闭change buffer的功能。
* 另外，如果我们经常要同时使用多个字段进行查询时，此时一般是需要建立一个复合索引，利用索引覆盖来加快索引的效率。

###### 对ClassLoader的理解
* 类加载大致分为两种：
  1. 数组类的加载，这种加载不涉及字节流，由Java虚拟机内部生成；
  2. 类和接口的加载。这种加载涉及字节流，需要ClassLoader辅助完成。
  * ClassLoader分为4种，平时一般用到的只有前三种：
  >1. BootstrapClassLoader启动类加载器，负责加载jre/lib/rt.jar中的类
  >2. ExtensionClassLoader扩展类加载器，负责加载jre/lib/ext目录下的.class和.jar中的类
  >3. ApplicationClassLoader应用类加载器，负责加载ClassPath路径下的类，一般是用户自己写的类。
  >4. 另外还有一种是自定义类加载器，可以自行制定类加载的规则，通常用于需要加密的类，防止字节码被反编译。

  * 双亲委派机制
  >类加载器从上到下是依次启动类加载器、扩展类加载器、应用类加载器，上层是下层的父类，下层是上层的子类。
  下层的类加载器收到类加载请求后，首先询问父类加载器是否加载，逐层向上传导至顶层。如果不能加载（要加载的类不在自己工作目录下），在下推加载权利给子类加载器去加载。
  双亲委派机制的主要目的是防止某些类被重复加载。

* 类加载机制  
  * 类加载分为加载、链接、初始化三大步骤：
    1. 加载：顾名思义，就是将.class字节码文件加载进内存中.
    2. 链接分为验证、准备、解析三个阶段：
      * 验证：检查字节码格式是否符合规范；
      * 准备：为这个类分配内存空间，包括其中的静态变量，默认初始化为全0。还有用于实现运行时多态的方法表，其中包含了所有方法的符号引用到直接引用的映射。
      * 解析：将符号引用替换成直接引用。
    3. 初始化：从上到下按序执行类中的静态变量赋值语句、静态代码块，这些统一归为clinit方法，利用反编译技术可以看到代码中有clinit的符号引用。

### 3.1
###### 拥塞控制（慢开始，快重传、拥塞避免、快恢复）
TCP通过拥塞窗口cwnd来实现拥塞控制，目的是防止网络过度拥塞。cwnd限制了发送方一次可发送的字节数，拥塞控制有4种算法：
1. 慢开始
初始cwnd为1，之后以指数级增长，每次发送前都会将cwnd增长到上一次的2倍，直至长到ssthresh，转为拥塞避免算法。
2. 拥塞避免
初始cwnd为ssthresh，之后呈线性增长，即每收到对一个字节的ACK后就增长1。
3. 快重传
当接收方收到了M1,M2,M4这3个分组时，会返回对M2的ACK，表示希望接收到的下一个报文段是M3。此时发送方如果连续收到3个对同一报文段的确认，就会快重传这个丢失的报文段。由于只丢失一个报文段，因此不是网络拥塞，于是接下来开始快恢复。
4. 快恢复
令ssthresh=cwnd/2,cwnd=ssthresh，此时直接进入拥塞避免状态。

###### 流量控制（零窗口的含义、接受窗口的协商）
TCP接收方发送的报文中TCP头部有一个滑动窗口字段，用于告知数据发送方自己接受缓存的大小，从而控制发送方的发送窗口，防止因为发送过快而出现数据接收不过来的情况，这叫流量控制，与网络拥塞无关。
如果是零窗口，说明当前接收方的缓存已经满了，不能再接收数据，于是发送方需要暂停发送数据，等待接收方将缓存空出来，然后返回PSH报文告知发送方可以发送了。如果长时间没反应，发送方会发送PSH报文催促接收方尽快将缓冲区的数据交给应用。

###### 对String及其不可变性的理解
* String是被声明为final的，即不可以被继承。Java 8中使用char[]数组来储存数据，Java 9开始改用byte[]储存。
* String的不可变是指一旦给定了一个字符串对象，其中的字符串就不可修改，只能创建新的字符串对象。
* String不可变有4大好处：
  1. 缓存hash值：因为String的hash经常被使用，比如作为HashMap的key来使用，String不可变的话，hash值就仅需计算一次。
  2. String Pool的需要：如果一个String对象已经被创建过了，就能在String Pool中取得引用。只有String不可变，才可能使用String Pool。
  3. 网络安全：在进行信息通信时，参数往往都是以字符串的形式传递。如果字符串可变，很容易就会被篡改，导致信息不一致。
  4. 线程安全：String的不可变性本身就保证了线程安全，可以在多线程间安全地使用。
* String Pool的理解
  * String Pool用于存储字符串字面量，这些字面量在编译期间就确定。在Java 7之前String Pool放在运行时常量池中，属于永久代，但是由于永久代空间有限，在需要大量使用字符串的场景下会出现OOM的问题，因此从Java 7开始移到了堆中。
  * 执行如下语句时，如果String Pool中还没有这个字面量和指向该字面量的String对象，则会生成2个String对象。首先在String Pool中生成一个String对象sp，其value指向字面量"aaa"。然后在堆中生成一个String对象，sp作为参数传入拷贝构造函数。
  ```Java
  String s1 = new String("aaa");
  ```
  最终调用的构造函数如下：
  ```Java
  public String(String original) {
      this.value = original.value;
      this.hash = original.hash;
  }
  ```
  可以看到新对象并没有完全复制字符串，而是指向了同一个value引用。这叫做浅复制。
  * 还可以在运行过程中通过stringObj.intern()方法将字面量加入String Pool中，如果String Pool中查到已经有了这个指向这个字面量的String对象，就会直接返回这个String对象的引用。如果没有，在Java 1.6中会在String Pool中新建一个String对象指向这个字面量，然后返回这个新对象的引用。而在Java 1.7中会在String Pool中加入这个字面量与stringObj的引用，不会再新建实例对象。这种优化的目的主要是为了节省内存。
  >StringDemo及其说明如下
  ```Java
  //编译期间会确定"ab"和"cd"这两个字面量，运行时首先在String Pool中生成这2个字面量和对应的实例对象，然后在toString的时候在堆中生成实例对象ss1，value="abcd"也是在堆中生成，String Pool中不会生成"abcd"的字面量。
  String ss1 = new String("ab") + "cd";//<=> String ss1 = new StringBuilder("a").append("bc").toString();
  //Java 1.6：在String Pool中生成新的实例对象和字面量"abcd"，返回新对象的引用
  //Java 1.7：将堆中实例对象的引用连同字面量加入String Pool，返回ss1对象的引用
  String intern_ss1 = ss1.intern();
  //Java 1.6：false
  //java 1.7：true
  System.out.println(ss1 == intern_ss1);
  //在String Pool中查到了"abcd"字面量及其映射的引用
  //Java 1.6：返回String Pool中的对象的引用
  //Java 1.7：返回堆中ss1的引用
  String ss2 = "abcd";
  //Java 1.6：false
  //Java 1.7：true
  System.out.println(ss1 == ss2);
  //在堆中生成新的实例对象ss3
  String ss3 = new String("a")+"b";
  //由于第1行已经将"ab"加入常量池，因此String Pool中已经有了"ab"对应的实例对象，此时直接返回String Pool中的对象引用
  String intern_ss3 = ss3.intern();
  //均为false
  System.out.println(ss3 == intern_ss3);
  ```
  不用intern的情况(结果上Java 1.6与1.7一致)：
  ```Java
  String ss1 = new String("ab") + "cd";
  //在String Pool中加入字面量"abcd"，并生成新的实例对象指向该字面量，返回新对象的引用
  String ss2 = "abcd";
  //均为false
  System.out.println(ss1 == ss2);
  ```

### 2.29
###### 面向对象的特性
封装、继承、多态。
* 封装就不用多说了。
* 继承是一种类间关系，子类继承父类，意味着子类拥有父类的非私有成员，并且可以重写父类的成员函数。所有抽象类和无显式继承关系的类都默认继承实体类Object，因此可以用Object引用指向所有的对象。
* 多态分为编译时多态和运行时多态。这种多态是通过类对象的方法表实现的。编译后会将调用方法的代码转换成invoke助记符+方法标签的形式，而动态方法的具体入口地址要在运行时从类加载进来的方法表中查找得到（静态方法无需加入方法表，在运行时直接用相对类对象的偏移量替换）。
  * 编译时多态是指在编译期间就确定了要使用的方法是哪一个。比如同一个类中方法的重载，编译期间根据参数就能知道具体要调用哪个方法表中的哪一个方法，在字节码中表现为方法标签的差异，这是静态绑定。
  * 运行时多态是指必须在运行的时候才能知道具体要调用哪一个方法。比如多个子类继承同一个父类，用父类的引用去指向不同的子类对象，并调用重写的非静态方法时，在运行时才能知道要调用的是哪个子类重写的方法，在字节码上表现为方法标签相同，但是运行时会从局部变量表中拿到不同对象的引用，去不同的子类中查找相应的方法表，这叫做动态绑定。这种多态的特性可以使得程序更加简洁统一，在不同情况下要调用不同子类方法，用一个父类引用分时指向不同的子类对象即可，而不用刻意去创建子类的引用，更加灵活。但是有一个弊端就是父类引用不能访问子类独有的成员，因此出现这种需求时仍需要特殊处理。

###### 谈谈你对接口和抽象类的理解
* 抽象类和接口都是不能被实例化的。接口可以看做是抽象类的延伸。
* 抽象类中的成员方法可以实现也可以不实现。成员的访问权限可以是public、protected、private任意一种。抽象类可以被多个子类继承，但是一个子类不能继承多个父类。其继承关系具有严格的类层次要求。
* 接口中的成员都必须是public，字段均默认为static和final的。在Java 8之前，接口中的方法均不能有默认的方法实现。当其他类实现该接口后，必须要实现其中的所有方法，因此如果要对接口进行改动，增加成员方法的话，就要改动实现了该接口的所有类，维护成本较高。从Java 8开始，接口中的方法也可以有默认的方法实现（用default声明），这样就降低了修改接口的成本。接口可以被多个类实现，一个类可以实现多个接口，打破了类继承严格的类层次限制，灵活性更强，再加上Java 8对接口的改进，我们可以说接口优先于抽象类。
* 不过事无绝对，在不同场景下有不同的选择。
  * 3种情况下需要使用抽象类
    1. 相关的类之间需要共享代码时；
    2. 要能控制继承来的成员的访问权限，而不是全为public；
    3. 要继承成员变量是非static和非final的。
  * 2种情况下用接口
    1. 需要让不相关的类实现同样的方法。比如不同的类都可以实现Comparable中的compareTo方法；
    2. 需要多重继承来继承多个类中的方法时，不如直接实现多个接口，简化继承关系。
* 接口可以继承接口，比如List继承了Collection；抽象类可以实现接口；抽象类可以继承实体类，比如所有的抽象类都继承自Object类。

### 2.28
###### 为什么TCP中的初始化序列号要是随机的？
如果初始序列号是固定的，很容易被攻击者猜出后继序列号，并且伪造序列号进行攻击，这已经成为了一种常见的网络攻击手段。鉴于网络安全的问题，初始序列号随机化可以一定程度上减少这种攻击手段成功的概率。

###### 三次握手的时候双方会交换什么数据？
首先是双方发送的TCP报文的序列号(ISN)，其次是自己的端口号，滑动窗口的大小，最大消息长度、是否支持SACK等。

###### 对SACK的理解
* SACK（选择确认）是TCP首部的一个选项，用于对非连续字段进行确认。如果通信双方都支持SACK，则可以在建立连接的时候设置SACK Permitted=true来打开SACK的选项。
* SACK一般由数据接收方生成，且一般是不携带数据的，只有TCP首部。在TCP首部中的选项中可以看到SACK字段，其中left edge表示左边界，right edge表示右边界。假设确认号=x，左边界=x+100，右边界=x+200，表示的是[x,x+100)内的数据还没有收到，而[x+100,x+200)的数据已经收到了，因此发送方仅需重发[x,x+100)的数据即可。
* SACK解决的是普通确认原则下导致的效率问题。以上面的情况为例，在没有SACK的情况下，[x+100,x+200)的数据会放在接收方缓冲区，然后接收方只会返回ackNum=x的ACK包，发送方收到后只会认为x之后的数据都丢失了，于是重传x之后的所有数据，非常浪费时间，极大降低了传输的效率。而SACK就只需重传丢失的那部分数据即可。
* 由于TCP首部的选项最多只能40字节，SACK字段的一对边界就占了8个字节，4对就32个字节，再加上Kind和Length的2个字节，就只剩下6个字节。这意味着SCAK最多只能告知4个以接收到的数据段。

>参考资料：[TCP-IP详解：SACK选项（Selective Acknowledgment）](https://blog.csdn.net/wdscq1234/article/details/52503315)  
[29-tcp可靠传输——选择确认选项（SACK）](https://blog.csdn.net/qq_35733751/article/details/80157509)

### 2.27
###### 聚集索引和非聚集索引
* 聚集索引将表数据都放在索引树上，每一个叶子节点都是一行数据，查找的依据一般都是主键。InnoDB的主键索引就是用聚簇索引实现的。
* 非聚簇索引的叶子节点只存放对应数据的地址，查找的依据可以是主键也可以是非主键索引字段。MyISAM就是使用非聚簇索引，真正的表数据都放在另一块内存空间中。
* 聚集索引的好处就是只需一次查询就能获得自己想要的列数据，而非聚集索引不一定能直接得到自己想要的列，所以可能需要二次查询，效率更低。但是非聚集索引更加轻量，适用于使用非主键索引进行查询的场景。

###### AtomicInteger，原理是什么，如何做到高效率的，有什么优化措施
* AtomicInteger是对int的封装，提供原子性的访问与更新操作，其原子性操作的实现是基于unsafe类的CAS。CAS，即compare and swap(比较和交换)，涉及3个操作数：要更新的内存值V，进行比较的值A，拟写入内存的值B。CAS会先将V与A进行比较，如果相等，就将B赋值给V，如果不等，则开始自旋，进行下一次CAS。
* Java中CAS的底层是调用了C++的本地方法，本地方法再调用CPU指令集，通过基于硬件的原子操作来实现CAS的原子性和高效性。
* AtomicInteger的LongAdder就是一个优化措施，通过分段来降低并发度，将多线程竞争1个资源变成了多线程竞争n个资源，比如使用cell[4]这样的数组。如果要获取数据，就将4个cell数据相加返回，如果要修改数据，就修改自己当前被分配到的cell资源。比如线程A分配到cell[0]，线程B分配到cell[1]。A执行getAndIncrement操作的过程就是将4个cell相加作为返回值，然后将cell[0]进行原子性的加一操作（即CAS）；B执行decrementAndGet操作的过程则是先将cell[1]进行原子性的减一操作（即CAS），然后将4个cell相加并返回。

###### 悲观锁和乐观锁
* 悲观锁假设最坏的情况，总认为自己去拿数据的时候别人会来修改。而乐观锁则是假设最好的情况，每次都不会有其他人来修改数据。
* 悲观锁的典型实现有synchronized和Reentranlock，通过加独占锁的方式使得其他要来修改数据的线程被阻塞。
  * synchronized是一种非公平机制的锁，每次释放锁时，所有锁池中的线程均可竞争锁，虽然不公平，但是保证了高吞吐量。
  * Reentranlock有公平和非公平两种机制，公平就是先到先得，后到排队，非公平就是每个新到的线程都会去尝试拿锁，拿不到了再乖乖排队等候，如果没轮到自己当队头，之后都不能竞争锁，这与synchronized的非公平不太一样。
* 乐观锁的典型实现有版本号机制和CAS算法。
  * 版本号机制会有一个version记录修改次数，每当要更新一个数据时，会同时取出数据和对应的版本号version，更新完数据要写回时，会先检查版本号是否和原来一致，如果一致就将版本号加一，然后同时将版本号和数据刷回去，如果不一致，此次提交就会被驳回。
  * CAS，即compare and swap（比较与交换），先比较后更新，涉及3个操作数：要更新的内存值V，进行比较的值A，拟写入的新值B。如果V==A，就将B赋给V，CAS成功；否则CAS失败。通常与自旋操作搭配使用，失败就取新值继续比较，直至CAS成功为止。
* 下面我讲讲synchronized与CAS的应用场景
  * synchronized一般用于线程冲突严重（资源竞争严重）的场景，如果这种场景下使用CAS的话，大概率会导致线程自旋，白白消耗CPU资源，而用synchronized加锁的话，会直接阻塞线程，避免CPU资源的浪费。
  * CAS一般用于线程冲突较轻（资源竞争较少）的场景，如果这种情况下使用synchronized的话，线程都不会被阻塞太久，此时的线程阻塞唤醒切换、用户态内核态的切换等操作反而会额外消耗CPU资源；而CAS基于硬件实现，不需要进入内核，无需切换线程，同时自旋概率较小，因此性能更高。
>参考资料：[面试必备之乐观锁与悲观锁](https://blog.csdn.net/qq_34337272/article/details/81072874)
[简述乐观锁和悲观锁](https://blog.csdn.net/qq_32600929/article/details/89089577)


### 2.25
###### 垃圾回收机制GC，cms，G1，垃圾回收的算法
常见的垃圾回收器有Serial和Serial Old，ParNew和CMS，以及G1回收器。  
* Serial和Serial Old都是单线程的回收器，前者针对新生代，后者针对老年代。现在Java后端基本不怎么用了。  
* ParNew是针对新生代的支持多线程并发的GC，使用复制算法对新生代垃圾进行回收，将堆内存中的新生代划分为一个Eden区和2个Survivor区，比例一般设置为8:1:1。在运行过程中总会预留一个空闲的Survivor区，举个例子，在某次回收时会将Eden区和S1的存活对象复制到S2区，然后清空Eden区和S1区，接下来只有Eden区和S2区存放对象，直至下一次回收，又将存活对象搬至S1区，清空Eden和S2区，如此往复。  
* CMS是针对老年代的支持多线程并发的垃圾回收器，回收过程要经过初始标记、并发标记、重新标记、并发清理4个步骤。初始标记会让系统线程停止工作，进入Stop the World状态，然后将GC Roots直接引用的对象标记为存活对象；并发标记让系统线程恢复运行，同时进行GC Roots跟踪，将所有GC Roots间接引用的对象都找出来并标记；重新标记又会进入Stop the World，将上一步并发标记过程中发生变化的对象标记出来，包括哪些对象变成垃圾对象，哪些对象是新产生的；并发清理阶段又会让系统线程恢复，然后并发地去清理之前标记出来的所有垃圾对象。由于清理完后，老年代内存空间中的存活对象一般都是东一个西一个，很零散，因此会造成大量内存碎片，JVM有个参数可以设置每几次Old GC进行一次碎片整理。
* G1垃圾回收器也是支持并发线程的，同时负责清理新生代和老年代。并且可以手动控制其垃圾清理对系统性能的影响。
G1将堆内存划分成许多个Region，一般JVM中最多有2048个Region。
G1不明确划分新生代和老年代，而是在运行过程当中进行动态分配和动态转移。
所谓动态分配，举个例子，由于新生代最多占60%的空间，一开始新生代只占2%，然后在不断运行过程中新生代的对象占用会不断增长，直至增长到60%就会触发对新生代的GC。
而动态转移是指，当新生代的某个Region被清空后，这个Region下一次可能就被分配给老年代了。
值得注意的是，在G1机制中，大对象不属于老年代，而是单独分配Region，有可能一个大对象会横跨多个Region。
另外G1的新生代的内存分配依旧是一个Eden区和2个Survivor区，其比例一般也是8:1:1，比如某时刻新生代占了1000个Region，那么其中Eden区占800个Region，Survivor区各占100个，新生代的GC也是使用复制算法，与ParNew类似。
除了新生代触发的垃圾回收，还有老年代触发的混合回收机制。当老年代内存占比超过45%时，就会触发Mixed GC，在这个过程中会同时对新生代、老年代和大对象进行回收。GC过程分为初始标记、并发标记、最终标记、混合回收4个步骤。前三步与CMS的类似，区别在于最后一步。混合回收过程中会计算每个Region中存活对象占比、执行垃圾回收的预期性能与效率，选取部分Region进行回收，保证清理时间不超过预先人为设定的时间。这样**控制GC时间**就保证了垃圾清理不会对系统性能造成太大的影响。实际上在G1中会记录每个Region的垃圾占用，并据此维护一个**优先队列**，而清理的具体过程就是从优先队列中弹出部分垃圾占用较高的Region进行回收，另外还有一个规则，如果垃圾占用低于20%就不会去回收这个Region。注意在Mixed GC中的回收也是使用复制算法，将所有Region中的垃圾对象都复制到空闲Region中，然后一次性清理掉原来的Region，这样就避免了内存碎片的问题。

###### TCP连接和释放
* TCP连接建立过程要经过三次握手。假设一个客户端向服务端请求连接，需要经过如下过程：
1. 客户段发送TCP连接请求，即SYN包，其中SYN=1，ACK=0，假设序列号为x，然后客户端进入SYN-SEND状态。
2. 服务端收到SYN包后，确认可以建立连接，就返回一个ACK包，其中ACK=1表示这是一个确认报文，SYN=1表示这同时也是一个连接请求报文。另外，报文中的确认号为x+1，表示希望接收到的下一个报文序号。假设此包序列号为y，然后服务端从LISTEN状态进入SYN-RCVD状态。
3. 客户端收到ACK包后，返回一个对服务端的连接请求的确认报文，进入ESTABLISHED状态。该报文的SYN=0,ACK=1,序号=x+1,确认号=y+1。
4. 服务端接收到ACK报文后，进入ESTABLISHED状态。然后双方开始传输数据。

* TCP连接的释放需要四次挥手。假设客户端已经发送完了所有数据，可以断开连接了，但是服务器还没准备好，此时连接的断开需要经过如下步骤。
1. 客户端发送FIN包，主动请求断开连接，然后进入FIN-WAIT1状态。FIN包中的FIN=1,ACK=0,seqNum=u。
2. 服务端接收到FIN请求后，返回一个ACK，其中FIN=0,ACK=1,seqNum=v,ackNum=u+1，然后进入CLOSE-WAIT状态，此期间会通知应用尽快接收完所有数据。此时TCP连接进入半关闭状态，即只有被动断开连接的一方可以发送数据，另一方只能接收。
3. 服务端准备好后，向客户端发送FIN包请求断开连接，其中FIN=1,ACK=1,seqNum=w,ackNum=u+1，然后进入LAST-ACK状态，等待最后一次确认。
4. 客户端收到FIN包后，返回ACK包表示确认收到断开连接请求，其中FIN=0,ACK=1,seqNum=u+1,ackNum=w+1，然后进入TIME-WAIT状态，等待2MSL后进入CLOSED。
5. 服务端收到ACK后确认可以断开连接了，于是进入CLOSED。
我解释一下在这个过程的最后客户端为什么要等待2MSL再关闭连接。我们知道每个报文在网络中都有一定的生存时间，超过这个时间就会在网络中消失，这个最大报文生存时间叫做MSL。正常情况下报文会在远小于MSL的时间内到达目的地，如果没有到达，说明报文已经不可能到达了，我们此时一般会想要重传。TCP就有这个报文重传机制。当发出去一个需要确认的报文时，如果经过规定的时间T（一般小于2MSL）还没有收到ACK，说明报文有可能丢失了，于是会重新发送这个报文。在第3步服务端发出FIN包后，如果T时间后仍未收到ACK，就会重传这个包，此时客户端要做到就是等到这个重传的包到来，再次发送ACK，保证服务端能够收到ACK并关闭连接，释放端口，避免空等待。如果客户端在2MSL的等待中都没有收到重传的包，大概率是服务端已经收到ACK并正常关闭了，此时客户端便可安心关闭连接了。
>###### 假设说一台电脑上很多端口处于CLOSE_WAIT状态，是发生了什么事呢？
>>说明对应的应用程序出了问题，导致迟迟没有接收数据，因此线程也无法执行CLOSE方法让主机进入LAST-ACK状态。
>###### 如果一台电脑上有很多端口处于TIME-WAIT状态，是发生了什么呢？
>>说明存在很多短连接。


### 2.24
###### String，StringBuffer，StringBuilder区别
* String对象中所包含的是一个不可变字符串序列，一但定义了一个String对象，其中的字符便不可修改。
* StringBuffer对象中操作的是一个可变字符序列的字符缓冲区，实际上就是一个char[]，可通过append、insert、setCharAt等方法来修改字符串，最终通过toString转换成想要的字符串。
* StringBuilder与StringBuffer类似，唯一的不同点在于StringBuffer是线程安全的，而StringBuilder是不安全的。StringBuffer通过对每个方法都加上synchronized关键字的方式进行加锁，从而实现线程安全。但是在并发度较小的情况下建议使用StringBuilder，性能更高。

###### mysql的存储引擎有很多种，你有听过哪些？这些引擎有什么区别呢？
MySQL的存储引擎主要有MyISAM和InnoDB。
1. MyISAM不支持事务，InnoDb支持事务
2. MyISAM不支持行锁，InnoDB支持。
3. MyISAM可以没有主键，使用非聚簇索引；InnoDB必须要有主键，且使用聚簇索引来存储。
4. MyISAM会缓存表中行记录的总数，而InnoDB不会。因为MVCC机制有可能会在不同事务中生成不同的一致性视图，行总数在不同事务中可能是不同的，因此缓存行总数是无意义的。
>其他的区别在版本升级的过程中已经逐步同化了，比如MySQL 5.6之前只有MyISAM支持全文索引，在MySQL 5.6之后InnoDB也开始支持全文索引了。

###### ip头tcp头udp头这些能不能介绍一下？
1. IP头是网络层的东西，固定部分的长度为20字节，其中包含的主要字段有源IP地址、目的IP地址、版本、首部长度、总长度、首部检验和等，我着重介绍一下其中比较有趣的一些字段。
* 标识和片偏移：当数据报过长，超过了一个IP数据报所能容纳的最大长度时，需要进行分片。相同数据报的不同分片具有相同的标识符，片偏移和标识符一起使用，表示当前IP包相对完整数据报首地址的偏移量，片偏移以8个字节为单位。
* 生存时间TTL：这个字段表示可经过的最大路由数，是人为设定的，用于防止不可交付的数据报一直在互联网中兜圈子，以路由器跳数为单位，每经过一个路由器就减一，当TTL减为0时，路由器就会丢弃这个数据报。这字段一般在进行Traceroute的时候使用，用于跟踪从源主机到目的主机的途径的所有路由IP。
* 协议：指出携带的数据要上交给哪个协议去处理，比如ICMP、TCP、UDP。
2. TCP头的固定部分也是20字节，主要字段有源端口、目的端口、序号、确认号、数据偏移、检验和等等，我简要说下其中的部分字段。
* 序号：每个TCP报文都会有一个序列号，用于标识当前TCP报文数据部分的第1个字节在本次TCP连接中的编号，加入当前序号为200，数据部分长度为1字节，那么下一个TCP报文的序号就是201。
* 确认号：当标志ACK为1时有效，表示这是一个确认报文，确认号是期望收到的下一个TCP报文的序号。一般只会对携带数据的、携带SYN的、携带FIN的TCP报文进行确认。
* 数据偏移表示数据部分相对于TCP首地址的偏移量。
* 窗口：是接收方用于告知发送方设置发送窗口的依据，因为接收方的接收缓存有限，发送方需要控制一次性发送的字节数。
* 紧急指针：当URG标志为1时，该字段有效，此时该报文中的数据部分会分为紧急数据和普通数据，紧急指针指向的是紧急数据的最后一个字节，之后的便是普通数据。当主机收到这样的TCP报文，会优先处理其中的紧急数据，尽管它们还没有进入滑动窗口。
* 标志：RST、SYN、ACK、FIN、PSH、URG共6个标志位，每个标志位占用1个bit，其中SYN、ACK、FIN都比较常见，URG在前面紧急指针的介绍中提过，剩下的RST是连接复位标志，收到此包的进程会将回滚到建立TCP连接前的状态。而PSH是用于催促发送方赶紧把缓冲区的数据发送出来或者催促接收方赶紧把缓冲区的数据交给应用。
3. UCP头比较简单，只有8个字节，包括的字段有源端口、目的端口、长度、检验和。除此之外还有一个12字节的伪首部，里面主要是源IP、目的IP、UDP长度这些信息，是用于计算检验和而临时添加的。

### 2.23
###### 进程如何同步
1. 信号量  
信号量本质就是一个整型变量，通过P和V操作来控制同步进程对临界区的访问。所谓临界区，就是一段对临界资源进行访问的代码。  
P、V操作都是原子性的操作，通过在运行期间屏蔽中断的方式来实现原子性。P将信号量s的值减一，V则将s加一。s的初始值表示能同时进入临界区的进程数目。如果s为非正数，P操作将其减一后会将调用P方法的进程加入阻塞队列。V则从阻塞队列中释放出一个进程。

2. 管程  
一般用于解决生产者消费者问题，相比信号量，省去了很多控制代码。管程的特点是只能有一个进程进入管程，其他进程都将被阻塞。管程通过使用2个条件变量full和empty的wait()和signal()操作来控制生产者和消费者的行为，避免向满缓冲区中插入东西或者消费空缓冲区。

3. 消息队列  
消息队列实际上是以一对原语来实现其功能，分别是send和receive，指明接收方和发送方以及要传递的消息。这样当一个进程执行完一段互斥代码后就可以调用send操作通知指定的被receive阻塞的进程去执行这段代码。

###### 谈谈你对TCP中确认原则的理解
TCP最大的特点就是确认原则，解决的是能不能通信的问题。  
有3种报文收到后需要确认：携带数据的、携带SYN的、携带FIN的TCP报文。  
有2种报文是无需确认的：不携带数据的ACK报文、携带RST的报文。  
另外，TCP进行确认的时机也是很有讲究的。由于返回ACK报文也要消耗一部分CPU资源，因此每次都返回ACK的话，开销会增大，CPU处理TCP报文的时间会变长。因此现在一般都是每收到2个报文再返回对后面这个报文的ACK，这叫做*延迟确认**（Delayed ACK）。但是如果第一个报文发来很久都没有收到第二个报文，此时会有一个Delayed ACK定时器（Timer）进行检测，一旦超时，就会赶紧将ACK发出。

###### TCP/IP层的一些专用概念
RTT：报文往返时间。  
RTO(Retransmission Timeout)：最大报文超时重传时间。  
MSL(Maximun Segment Lifetime)：最大报文段寿命，与TTL有关，但MSL更大。  
TTL(Time To Live)：IP数据报可经过的最大路由数。是IP层的概念。

###### TCP头部是怎样的
TCP头部有20个固定字节，里面包含了目的和源端口号，序号、确认号、数据偏移、窗口、检验和、紧急指针、RST、PSH、URG、SYN、FIN、ACK等字段。
* 序号是当前TCP报文中的数据部分的第1个字节在整个字节流中的编号（即第几个字节）。  
* 确认号是期望收到的下一个TCP报文的序列号。  
数据偏移是该TCP报文中数据部分的首地址相对于TCP报文首部的偏移量。  
* 窗口值是接收方让发送方设置其发送窗口的依据，用于告知发送方一次性最多发送几个字节，因为接收方的接收缓存有限，这就是TCP的流量控制。
* 紧急指针：当URG字段为1时有效，指向的是紧急数据的最后一个字节，之后的都是普通数据。
* RST是连接复位字段，让接收到此包的进程回滚到建立TCP连接前的状态。
* PSH字段用于催促接收方尽快将缓冲区的数据交给应用或者催促发送方尽快将缓冲区的数据发送出来。
* URG是紧急字段，用于声明这是一个包含紧急数据的TCP报文，与紧急指针配合使用。
* SYN是同步字段，表明当前正在建立TCP连接。SYN=1,ACK=0时表明这是一个连接请求报文。
* ACK是确认字段，为1时表明这是一个确认包，确认已经收到了对方发来的TCP报文，与确认号配合使用。
* FIN是结束字段，为1时表明要请求关闭连接。

###### TCP的头部除了SYN、ACK外，还有哪些标记位？它们都有哪些作用
* RST(连接复位)字段  
RST为1时，接收到RST包的一方将回退到建立TCP连接之前的状态。
1. SYN被发给了一个不处于listen状态的端口。
>此时OS发现监听这个端口的进程尚未处于listen状态，于是返回一个RST包。
2. 发送的SYN超时后又收到了ACK。
>此时OS拆开ACK包，发现本机上对应端口的进程已经关闭连接，于是返回一个RST包。
3. 宕机重启后收到了上一次TCP连接中传过来的信息。
>此时该TCP连接处于半开启状态，即一方意外中断，另一方仍然保持连接。OS发现找不到对应的进程来处理这些信息，就当是对方发错了，于是返回一个RST包。
4. 国家防火墙监控流量时发现有进程尝试进行非法连接。
>此时防火墙会伪造RST包发给正在建立连接的两台主机。

* PSH字段  
1. 当数据接收方发PSH给发送方时，意在催促发送方赶紧把包发过来，不要老放在缓冲区里。  
2. 当数据发送方发PSH给接收方时，旨在催促接收方赶紧把数据交给应用层，不要老放在缓冲区。

* URG字段  
URG字段表明一个报文是否是紧急（urgent）报文。  
URG为1时，紧急指针有效，指向的是紧急数据的最后一个字节，该字节之后的数据都是普通数据。  
接收方收到这个TCP报文后放在缓冲区中，即使没有进入滑动窗口（或者窗口大小为0），也会预先处理这个TCP报文中的紧急数据。

### 2.22
###### HTTPS加密了什么内容
HTTPS就是加了一层TLS的HTTP。而TLS是属于会话层的协议，介于应用层和传输层之间，TLS和HTTP协议共同为用户提供安全的访问网页的服务。  
HTTPS实际加密的只有HTTP头和内容，数据的发送方和接收方在建立TLS安全连接的时候交换的对称秘钥可以解开，任何没有秘钥的第三方都无法获取其中的明文，但是仍然可以获取TLS、端口、IP等的内容。

###### 邮件传输安全吗？
用户登录时通过HTTPS交换了相关的Session ID、Access Token、对称秘钥等私密信息。发送方使用SMTP协议进行邮件的安全发送，使用TLS对邮件内容加密后发送给服务器。服务器使用POP3/IMAP安全接收邮件，使用TLS解密获取明文。
但是邮件传输有一个致命的弱点，如果建立TLS连接总是失败，那么就会退而求其次，直接明文传输。HK就可以利用这一缺陷，从中作梗，人为的让双方连接过程中不停丢包，失败了一定次数后就会使用明文传输，这样HK就可以窃取邮件内容。所以并不安全。

###### 网关、路由器、三层交换机之间的区别在哪？
* 网关只是一个抽象概念，具体可以通过路由器、三层交换机、三层防火墙来实现，它们都是三层接力设备，可以处理IP报文头，主要用于转发跨网段的数据包。
* 路由器和三层交换机都是用来连接不同的网段，做一些数据包转发的工作。不同点在于硬件架构不同，三层交换机优化转发效率，而路由器的接口更丰富。

>* 网桥：二层交换机，是二层接力设备，也可以完成信号的转发，但是只能处理二层的以太帧头。
* 集线器/信号放大器：是一层接力设备，也能转发信号，但是只能处理物理信号，无法理解信号内容。

###### 进程间通信有哪些方法？
1. pipe：匿名管道，只能用于父进程与子进程之间的半双工通信。
2. FIFO：命名管道，可用于同一主机内任意两个进程间的通信，常用于客户-服务端应用程序中，FIFO作为汇聚点，在客户端进程和服务端进程之间传递数据。FIFO同步管道由读写进程创建，通过fd来访问同一个管道，从而实现进程间通信。这个管道随着读写进程的关闭而销毁。
3. 消息队列：不同于FIFO，消息队列进程独立于读写进程。
>~~（面试不用说）消息队列具有以下优点：
(1)消息队列独立于读写进程，由消息队列这个进程来负责统一管理，避免了FIFO的同步打开与关闭困难（如多进程打开文件时的重名问题，此时其他同步进程将出现报文件打开失败的错误）。
(2)读写进程仅需调用消息队列的API进行读写操作，不用自己提供同步方法，避免了FIFO的同步阻塞问题。
(3)消息队列中可以存放很多个打开的fd，读进程可以根据需要读取特定类型的消息。但是FIFO只能存放一个fd，读进程一股脑的读一堆进来，然后再将不需要的舍弃。~~
4. 信号量：就是一个计数器，用于同步多个进程对共享数据对象的访问。
5. 共享存储：多个进程共享同一块内存。具体来说是将这块内存映射到进程内的地址空间中，不用在内核空间中创建该存储块的fd，直接通过用户空间中的逻辑地址就能访问到同一个存储块的物理空间。这种方式需要使用信号量来同步对共享存储的访问，仅适用于要共享大块数据时。
6. Socket：用于跨主机或跨LAN的进程间通信。

>参考资料：
* [目前linux进程间通信的常用方法是什么(pipe？信号量？消息队列？)?](https://www.zhihu.com/question/23995948)
* [进程间通信-管道](https://zhuanlan.zhihu.com/p/106222551)
* [semaphore和mutex的区别？](https://www.zhihu.com/question/47704079)

### 2.21
###### 谈谈你对线程池的理解
线程池的思想有点类似于IoC，也是控制反转。将手动创建线程变成了由机器自动创建线程，根据系统情况调整线程数目，降低了内存的消耗，并减少了创建和销毁线程的次数，每个工作线程可被重复利用。

###### 浏览器输入完url按下回车开始到返回页面的过程
假设使用的是HTTP协议。
1. 浏览器先查询本地host，如果没有匹配的URL，就向DNS服务器发送查询请求，本地域名服务器向根域名服务器查询一般使用迭代查询。浏览器收到正常回复后即拿到对应的IP地址。
2. 浏览器生成一个HTTP请求报文，交由OS的传输层，将这份HTTP请求拆分成字节流，套上TCP头，交给网络层。
3. 网络层对收到的TCP数据流进行分组，生成IP包，交给链路层。
4. 如果IP属于外网，会将MAC地址设置成路由器的MAC；如果是内网IP，就查询本地ARP缓存，如果没有记录，就向路由器发送ARP请求，取得对应机器的MAC地址。这里假设IP属于外网。
5. 链路层给IP包套上MAC头，然后将生成的MAC帧交给物理层。
6. OS将完整的帧发送出去，路由器收到后，根据IP层的目标IP地址，加上下一跳的MAC地址，进行相应的转发。
7. 经过若干次转发后，到达目标局域网的路由器（即最后一跳）。路由器取下IP头，发现这个包是发给自己管辖的局域网内的主机，没有下一跳了，于是进行ARP，获得目标主机的MAC地址后，发送到自己的局域网下。
8. 目标主机收到了这个包，接收过程是发送过程的逆过程，最终这个HTTP请求报文会被交给监听对应端口的进程去处理。
9. 进程处理好后，会生成一个HTTP响应报文，经过同样的过程，层层封装好后发给我们的浏览器。
10. 浏览器收到HTTP响应报文后，取出其中的html内容，然后就可以展示这个完整的网页了。
[Linux系统下搭建DNS服务器——DNS原理总结](https://zhuanlan.zhihu.com/p/31568450)

### 2.20
###### 什么叫做JIT compiling，与传统的编译技术有何不同。
JIT，Just-In-Time，是即时的意思，即时编译器也叫做热点编译器，是一种动态编译器。

不同于C/C++的静态编译，JIT compiler是运行时编译（Runtime Compilation），一般应用于Java虚拟机中。Java解释器会将热点代码（即频繁被执行的字节码）交由JIT，JIT将其编译成本地（机器）代码，之后要执行的时候Java解释器便可直接调用，避免再次编译。

JIT compiler的作用对象是中间产物.class字节码文件中的热点代码，生成的是与本地平台适配的机器码。而字节码文件是由javac程序编译.java源代码文件得到的。

传统的编译技术是在程序运行之前进行全局编译，编译的对象是整个源代码，编译的产物就是可以直接执行的机器码。

###### HashMap，为什么使用红黑树
相比于链表，红黑树可以将插入和查询时间复杂度降到O(logN)，而链表的插入和查询都需要遍历整个链表，复杂度均为O(N)，当数据量极大时，效率将十分低下。不过在数据量较小的情况下还去维护一棵复杂的红黑树反而有点小题大做，因此在HashMap中设置了一个树化和链表化的阈值，数据个数大于前者，就将链表转换成红黑树，数据量小于后者，就简化成一条链表。
相比于二叉搜索树，红黑树可以在插入时自动调整左右子树的高度，防止左右高度相差太大导致查询效率降低。
相比于二叉平衡树，红黑树的平衡条件没这么苛刻，插入时所做的调整没这么频繁，效率更高，但是也不会太过降低查询效率，相当于在普通二叉搜索树和平衡树之间做了一个折中。

###### synchronized
每个对象都有一个Monitor数据结构，这个数据结构中又包含了锁池和等待池这两个数据结构。synchronized关键字用来修饰一个方法或者一个代码块，表示这段代码是临界区，同一时刻只能有一个线程进入临界区执行。具体实现是利用一个对象的Monitor，只有第一个拿到Monitor的线程才能进入临界区，其他线程将被阻塞在这个对象的锁池中，直至Monitor被释放，锁池中的线程才会被唤醒来竞争这个Monitor，拿到Monitor的线程将从锁池中移除，进入临界区，其他竞争失败的线程依旧留在锁池中等待下一次被唤醒。

### 2.19
###### java的基本数据类型和字节数
byte:1
char:2
short:2
int:4
float:4
long:8
double:8
boolean:?
>boolean可以用1bit来存储，但是没有明确规定其大小，JVM在编译时会将boolean型数据转换成int型，boolean数组则是当做byte数组处理。

###### Java，volatile关键字
volatile是指令关键字，用于修饰指令，主要有以下两大特性：
1. 可见性：保证每个线程都能看到最新的共享变量值。大致的实现方式如下：
假设有多个线程已经加载了共享变量val的副本到各自的工作内存中，此时线程A对val的值进行了更新并写入主内存，那么其他线程的工作内存中加载的val副本就会失效。当其他线程要用到val时，会发现工作内存中存放val副本的地址已经失效，就会重新去主内存中加载val的值进来。
2. 有序性：通过内存屏障（也叫栅栏）来防止编译器优化volatile声明的指令进行顺序重排。

###### mysql索引结构，特点，为什么使用这个
索引可以使用二叉搜索树、哈希表、B-树、B+树来实现。
1. MySQL采用B+树作为索引结构。
2. B+树的特点是树高比二叉搜索树低，这样查询数据时需要访问的层数可大大减少。
3. 原因：
* 与二叉搜索树相比，由于B+树是n叉搜索树，在同样数据量的情况下，B+树的高度不会过高。一般而言，索引的一个结点中的所有数据会存放在同一个扇区内，因此对索引每一层的访问都对应一次磁盘I/O，其时间主要分为2块，磁头移动寻找磁道的时间和磁盘转动寻找扇区的时间。故磁盘I/O的时间比内存I/O要长很多。因此减少磁盘访问次数就成为了提高数据库查询效率的关键点。
* 与哈希表相比，B+树支持范围查询，而哈希表不支持。
* 与B-树相比，B+树的非叶子节点不存储真实数据，而只会存放辅助查找的值，而B-树的真实数据分布在不同的层上，要进行范围遍历时会比较麻烦。B+树只要直接将所有叶子节点用双向链表进行组织，就可进行范围查询，非常方便。

>* 二叉平衡树：左右子树的最大深度之差不能超过1
* 红黑树：本质也是一棵二叉搜索树，规则是左右子树中更深的那棵子树的长度不能大于另一棵的两倍

###### ReentrantLock
* 重入锁，顾名思义，就是已经拿到锁的线程可以重复拿锁。
* ReentrantLock分为公平锁和非公平锁。
* 它们的区别在于当有新的线程想要拿锁的时候，公平锁只会让第一个线程去做拿锁的尝试，而后面的线程只能进入队列中等待；但是非公平锁会让每一个新来的线程都去进行拿锁的尝试，一旦锁刚好被释放，就有一定概率比队头的线程先拿到锁，就不用再排队，违反先来后到的公平机制，故是非公平的锁。

###### JMM
Java内存模型：将内存条划分为主内存和多个工作内存，每个线程都拥有一个工作内存。主内存用于存放共享变量，工作内存存放共享变量副本，线程不能直接操作主内存中的共享变量，需要将主存中的共享变量加载到工作内存才能够操作。
>不能与JVM内存分区混为一谈。JVM内存分区是物理上的划分，而JMM是逻辑上的划分。

### 2.18
###### 文件IO
每个文件file都有一个文件描述符fd，fd这个对象主要是用来指向文件所在地址。
当执行read操作时，会产生系统调用，内核会通过fd，从磁盘上文件的对应位置，以扇区(block)为单位，即4KB为单位加载进内核空间的页框（也是4KB）中，再从内核空间读取到用户空间的页框中，即完成一次读取（载入）操作。
当执行write操作时，也会产生一个系统调用，将指定的用户空间的n个内存页的内容写入内核空间的缓冲区，再写入磁盘的n个扇区。

### 2.17
###### 进程和线程，区别，哪个效率高，为什么
1. 定义：进程是资源分配的基本单位。线程是处理器调度的基本单位。
2. 区别：一个进程可拥有多个线程。每个进程都拥有自己独立的地址空间，而同一个进程内的线程共享该进程的地址空间。
3. 效率高低比较：
多进程并发与多线程并发没有绝对的效率高低，要视情况而定。  
如果是不同进程的线程切换，则与进程切换无异。  
如果是同一进程内的线程切换，则其成本和效率比进程切换效率更高。进程切换时，需要MMU进行缓存的刷新，即先清除前一个进程的缓存再加载后一个进程的缓存。但是进程内的线程切换无需进行如此大规模的MMU缓存刷新操作，开销较小。

###### 事务的特性，具体介绍
ACID
* 原子性：事务中的步骤要么不做，要么全做。
* 一致性：(选其一回答)
>抽象解释：事务执行的结果应该是使数据库从一种一致性状态变为另一种一致性状态。即哪怕事务被意外中断，其所做的修改不会更新到物理数据库上，即为一致性。
>举例解释：举个转账的例子，A转账给B一百块钱，要执行两步操作，首先从A的账户余额中扣除100，然后给B的账户余额增加100。这个转账操作必须是一个原子性的操作，否则，如果执行了第一步余额扣除操作，并同步到物理数据库上，此时事务突然被意外中断，第二步操作没有执行，那么A和B的总资产就变少了，此时就不是一致性状态了。

* 隔离性：并发执行多个事务，互不干扰。
* 持续性：事务一旦提交，其对数据库的改变就是永久性的。

###### 隔离级别，具体介绍
读未提交：所有事务可以看到其他未提交事务的执行结果。读未提交的数据，称为脏读。
读提交：所有事务只可以看到其他已提交事务的执行结果。
可重复读：在一次事务执行期间读到的数据都是一致的。
串行化：后来的事务必须等待前一个事务执行完毕才能开始执行。
>可重复读涉及到MVCC、undo log，普通读、当前读(for update)

###### 幻读
在不同时刻读到不同的数据的现象，就是幻读。
在MySQL中，通过将库的引擎设置为支持事务的引擎，如InnoDB，使用可重复读的隔离级别即可解决幻读问题。可重复读是通过在事务开始执行时生成一份一致性视图，即静态视图来实现的，在事务执行期间一直使用这份视图进行读操作，这样无论在什么时刻读都不会读到前后不一致的值。

###### 死锁的条件，如何解决
死锁是多个并发进程因争夺系统资源而产生相互等待的状态。  
* 必要条件：
1. 互斥：一个资源不能同时被2个进程占有
2. 占有且等待：一个进程可以无限期地占有某个资源，而另一个线程再等待它释放资源
3. 不可抢占：一个进程不能强行抢占另一个进程已经占有的资源
4. 循环等待：存在一个环形进程链，每个进程所需资源都被后一个进程占有
* 解决方案：
1. 死锁预防：破坏上述4个必要条件之一，比如占有且等待，可以在进程运行之前就为其分配好所需的所有资源
2. 死锁避免：在进程运行前预判，只允许不会导致死锁的进程申请资源。比如银行家算法，通过提前模拟一个进程拿到资源后的运行过程来判断是否会发生死锁。
