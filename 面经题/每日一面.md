### 3.12
###### map和unordered_map有什么区别？红黑树有什么特点？
map是用红黑树实现的，插入和删除都会进行调整，保证始终是排好序的，插入删除查询的时间复杂度都是O(logn)；unordered_map用哈希实现，是无序的，但是插入删除查询时间复杂度为O(1)，但是不利于范围查找。

###### 对于一个读多写少的大表，如果要增加一个字段，可以怎么做

###### 僵尸进程是什么

###### java泛型

>[对java泛型的理解](https://www.zhihu.com/question/23432488?tdsourcetag=s_pcqq_aiomsg)  
[java泛型理解和深入](https://zhuanlan.zhihu.com/p/40925435)

###### ThreadLocal，Concurrent下面的包，原理是什么，

###### Object类里面有哪些方法？解释一下几个重点方法
重要的方法有getClass/hashCode/equals/clone/notify和wait/finalize

>[从JDK源码角度看Object](http://cmsblogs.com/?p=5200&tdsourcetag=s_pcqq_aiomsg)

### 3.11
###### 如何查询比较高效
查询时尽量利用索引覆盖，而且不要做会导致索引失效的查询操作
	1. 查询时尽量使用最佳左前缀，即查询条件如果有多条，其条件检查的顺序要按照索引树的搜索顺序排列；
	2. 尽量不要使用通配符在前的like模糊匹配；
	3. 字符串一定要加上引号，否则会退化成普通查询，进行全表遍历。

###### 口述一下快排的思想
假设要将数组buf排列成非递减序列。
1. 首先，在数组中选取一个哨兵guard，比如buf[mid]
2. 用左右两个指针left,right指向数组的两端
3. left指针从左往右扫描，直至第一个不小于guard的元素为止，然后right从右往左扫描，直至第一个不大于guard的元素为止
4. 交换left和right指向的数组元素值
5. 如果left和right没有相遇，继续重复执行上述扫描操作；如果相遇，以right为分界线，将数组分为两段，分别用同样的方法递归处理这两段，递归出口是要处理的数组段不可再分。

### 3.8
###### 发生exception的时候是怎么进行try catch finally的？底层原理是怎么实现跳转的
在反编译字节码中可以看到有一个Exception Table字段，其中包含了exception的类型，from、to、target字段，如果从from到to的代码执行过程发生异常，就会跳转到target处处理异常。

###### 你有接触过设计模式吗？有听过哪些设计模式？单例模式是怎么实现的？
* 有单例、工厂、观察者等设计模式。
* 单例模式是指一个类只能有一个实例，并提供全局访问点。
* 单例模式是通过一个私有构造函数、一个私有静态变量、一个公有静态方法来实现的。私有构造函数是为了防止外界通过直接调用构造函数来创建实例对象，限制其只能通过调用公有静态方法返回唯一的私有静态变量，即单例。
* 单例模式有很多种实现方式：
1. 懒汉式-线程不安全  
不加锁，私有静态变量初始化为空。在公共静态方法中判断私有静态变量是否空，如果空，new一个新对象给它然后返回，如果不空，直接返回。  
很明显，在多线程并发的场景下，很有可能会有多个线程重复给私有静态变量赋新值，出现线程不安全的问题。
2. 饿汉式-线程安全  
不加锁，但是在类加载的时候就实例化，即初始化私有静态变量，之后调用公有静态方法时直接返回即可。
利用了类加载的线程安全机制，缺点是提前占用了内存资源，在有些时候是不必要的浪费。
3. 懒汉式-线程安全  
与<懒汉式-线程不安全>的区别在于，给公有静态方法加上了独占锁，用了synchronized修饰。  
虽然安全，但是可能会导致大量线程被阻塞在这个公有静态方法上，内核用户态切换频繁，导致效率下降。
4. 双重校验锁-线程安全  
在公有静态方法中的判空语句中再嵌套一个判空语句，并在第二个判空语句前加上独占锁。与<懒汉式-线程安全>相比，这种实现方式可以一定程度上降低线程阻塞概率，效率更高。
5. 静态内部类  
将私有静态变量定义及其实例化语句放在静态内部类中，只有当外部类调用内部类的这个变量时，内部类才会被加载进内存，在类加载的时候实例化语句才会执行。  
这也是利用了类加载的线程安全机制，与饿汉式不同的是，此方法只会在需要的时候才会加载类并实例化，节省内存资源，同时又实现了线程安全。
6. 枚举实现  
定义enum枚举类，其中定义一个枚举成员INSTANCE，默认为公有静态常量，并在类加载的时候被实例化，与饿汉式类似，只不过换了种定义方式。要使用该单例的时候直接用枚举类名.INSTANCE即可。
7. 乐观锁实现
在<懒汉式-线程不安全>的基础上，用CAS乐观锁的方式对公有静态变量进行赋值，保证所有竞争线程中只有一个能成功给该变量赋值，从而实现线程安全的单例。

###### 你了解http吗?http1.0 1.1有什么改进？
* HTTP是一种应用层的协议，用于规范传输应用信息的格式，便于网络信息交互。HTTP报文一般分为请求报文和响应报文。
  * 请求报文一般是客户端向服务端发送的，通过声明方法来确定该请求报文的目的，如GET就是向服务端请求数据，比如请求HTML文件用于呈现网页；POST会在服务端新增对象数据，比如用户在浏览器填写的表单字段；PUT是修改服务器的对象数据；DELETE是删除服务端的对象数据；HEAD是获取报文首部，一般用于检验URL是否有效；Connect是请求建立SSL/TLS安全连接（隧道）。
  * 响应报文是服务端返回给客户端的信息，状态码标明请求的结果状态，如200表示请求成功，一切正常，浏览器可以从实体中拿到需要的HTML/JSON文件；301表示永久性重定向；302表示临时性重定向；304表示该页面目前没有更新，无需返回新的数据；401表示客户端请求需要认证；403表示客户端请求被拒；404表示请求的页面找不到；500表示服务端正字啊执行请求时发生错误；503表示服务端超负荷或者正在停机维护。
* 相对于HTTP1.0，HTTP1.1做了部分改进。
  1. 引入Cookie：HTTP是无状态的，用于处理大量事务，但是有时候我们往往需要保存一些状态信息以免频繁去请求，因此HTTP1.1引入了Cookie来保存状态信息。Cookie存放在浏览器中，在每次向服务端发送请求时都会携带上Cookie信息，方便验证用户身份与更新状态。
  2. 默认长连接和流水线：HTTP1.0是默认短连接的，意味着浏览器的每次请求都要建立一个TCP连接，而这样一次TCP连接很少能通过slow-start区，不利于提高带宽利用率。因此在HTTP1.1中就改为了默认长连接，在一个TCP连接上可以发送多个请求和响应，减少连接建立和关闭的延迟与消耗。与此同时还增加了流水线机制，客户端不用等待上一个响应返回就可以直接发送下一个请求，极大地提升了下载速度，但是服务器返回的响应还是要按照顺序来，以便客户端能够区分出每条请求的响应内容。

### 3.7
###### 你有用过java的反射吗?java的反射可以拿来干什么？
* Java反射是通过调用Field/Method对象的API，来访问对象中的对应字段或方法。
* 这种反射通过调用Class对象的API实现的，而Class对象可以通过类名Object.class或者对象名object.getClass()获取。Class对象不是我们自己创建的，而是在.class加载进内存时由JVM虚拟机自动创建的，包含了一系列用于访问类元信息的API。比如class.getDeclaredField("字段名")可以获取A类中某个字段的Field，实则是该字段相对于类/对象首地址的偏移量。而class.getDeclaredMethod("方法名")可以获取Method对象。
* 如果该字段或者方法是私有或者保护成员，可以先调用Field/Method对象的setAccessible(true)方法设置访问权限，然后再通过Field/Method对象的get进行访问。如果一个对象的私有/保护字段没有set/get方法，而我们要去访问这些成员时，就要通过反射的方式进行读取/修改。
* Java的反射在一些框架中有所使用，比如spring的依赖注入。Spring用到的是IoC容器，即控制反转，就是将创建对象的控制权反转给spring，由spring去替我们去创建对象然后返回给我们使用，同时控制对象的生命周期，我们只需要配置xml文件声明我们需要的对象即可。此时就需要Spring来替我们进行对象中各个字段的注入。然后往往我们自己写的类，有时候会缺少一些get/set方法，这样Spring就无法替我们进行字段的注入，因此反射机制就显得尤为重要了。

### 3.4
###### mysql中什么时候索引会失效？
1. 没有使用最佳左前缀，会导致索引部分失效
2. 使用了通配符在前的like模糊查询
3. 字符串没有加引号  
2和3都会导致全表遍历查询。

###### tcp和udp有什么区别？
1. TCP支持可靠交付，保证送达；UDP只是尽最大可能交付，不保证送达
2. TCP面向连接，只能一对一通信；UDP不面向连接，支持一对一、一对多、多对多通信。
3. TCP有流量控制和拥塞控制，有效减少丢包和减轻网络拥塞；UDP只会一股脑地把报文发出去，不管对方接不接收得过来，也不管网络是否通畅。
4. TCP面向字节流，每个字节都有自己的序列号，保证数据报的有序性；UDP面向报文，接收和发送都是无序的。
5. TCP的传输过程安全可靠但是效率低，适用于追求绝对完整和安全的场景，如支付；UDP的传输简单高效，适用于追求实时性而不过度追求完整性的场景，如直播。
>拓展
TCP长连接与HTTP长连接

### 3.3
###### 如果一个sql查询太久了，有哪些可能的原因？
1. 连接故障：客户端与服务端之间的连接出现问题，发送的查询请求迟迟没有被服务端收到，或者服务端对应进程被阻塞/死锁。
2. 数据量大：sql查询基于非索引，因此需要遍历整张表来查询。同时数据量很大，遍历时间成线性增长，故需要查询很久。
3. 阻塞：表或者对应行被其他线程锁住，然后其他线程还迟迟没有commit，导致查询无法进行下去。
4. 使用了一致性读：在要执行sql查询的事务A开始后，事务B对要查询的记录执行了大量更新操作，产生了大量undo log，之后A才开始执行sql查询，于是需要读取这期间事务B写入的所有undo log，一步一步回到事务A开始执行的状态，从而得到一致性状态下的数据并返回。

###### 什么时候需要加索引？
* 经常要用到某字段进行查找时，需要基于该字段建立索引。我们平时经常用的一般是B+树实现的索引，如果索引值频繁被修改，就需要花费大量时间来维护这棵索引树，因此用一般是用读多写少的字段建立索引树。
* 索引可被分为唯一索引和普通索引。
* 如果需要确保业务更新操作过程中，表的某个索引不能出现重复值，就要使用唯一索引。否则，一般都建议使用普通索引+change buffer缓存机制。
* 在写多读少的场景下，需要进行频繁的磁盘IO操作，内存中的内存页要不断地更新，极大地影响效率和内存利用率。change buffer机制可以解决这种问题。
  * 如果一条SQL更新语句中要写的数据页不在内存中，会先将其更新操作存在内存中的change buffer中。待下一次对该数据页执行读操作时，再读出change buffer中关于该数据页的所有记录，对该数据页进行统一修改后再返回结果，这个过程叫做merge。
  * 这种机制可以极大地减少磁盘读的IO耗费，提高SQL语句的执行效率，同时节省内存占用。
* 在读多写少的场景下，很有可能出现每次在执行完一条写操作后立马就要对这个数据页执行读操作的情况，此时change buffer机制几乎无法再降低磁盘IO的次数，同时还要增加change buffer的维护成本，此时建议关闭change buffer的功能。
* 另外，如果我们经常要同时使用多个字段进行查询时，此时一般是需要建立一个复合索引，利用索引覆盖来加快索引的效率。

###### 对ClassLoader的理解
* 类加载大致分为两种：
  1. 数组类的加载，这种加载不涉及字节流，由Java虚拟机内部生成；
  2. 类和接口的加载。这种加载涉及字节流，需要ClassLoader辅助完成。
  * ClassLoader分为4种，平时一般用到的只有前三种：
  >1. BootstrapClassLoader启动类加载器，负责加载jre/lib/rt.jar中的类
  >2. ExtensionClassLoader扩展类加载器，负责加载jre/lib/ext目录下的.class和.jar中的类
  >3. ApplicationClassLoader应用类加载器，负责加载ClassPath路径下的类，一般是用户自己写的类。
  >4. 另外还有一种是自定义类加载器，可以自行制定类加载的规则，通常用于需要加密的类，防止字节码被反编译。

  * 双亲委派机制
  >类加载器从上到下是依次启动类加载器、扩展类加载器、应用类加载器，上层是下层的父类，下层是上层的子类。
  下层的类加载器收到类加载请求后，首先询问父类加载器是否加载，逐层向上传导至顶层。如果不能加载（要加载的类不在自己工作目录下），在下推加载权利给子类加载器去加载。
  双亲委派机制的主要目的是防止某些类被重复加载。

* 类加载机制  
  * 类加载分为加载、链接、初始化三大步骤：
    1. 加载：顾名思义，就是将.class字节码文件加载进内存中.
    2. 链接分为验证、准备、解析三个阶段：
      * 验证：检查字节码格式是否符合规范；
      * 准备：为这个类分配内存空间，包括其中的静态变量，默认初始化为全0。还有用于实现运行时多态的方法表，其中包含了所有方法的符号引用到直接引用的映射。
      * 解析：将符号引用替换成直接引用。
    3. 初始化：从上到下按序执行类中的静态变量赋值语句、静态代码块，这些统一归为clinit方法，利用反编译技术可以看到代码中有clinit的符号引用。

### 3.1
###### 拥塞控制（慢开始，快重传、拥塞避免、快恢复）
TCP通过拥塞窗口cwnd来实现拥塞控制，目的是防止网络过度拥塞。cwnd限制了发送方一次可发送的字节数，拥塞控制有4种算法：
1. 慢开始
初始cwnd为1，之后以指数级增长，每次发送前都会将cwnd增长到上一次的2倍，直至长到ssthresh，转为拥塞避免算法。
2. 拥塞避免
初始cwnd为ssthresh，之后呈线性增长，即每收到对一个字节的ACK后就增长1。
3. 快重传
当接收方收到了M1,M2,M4这3个分组时，会返回对M2的ACK，表示希望接收到的下一个报文段是M3。此时发送方如果连续收到3个对同一报文段的确认，就会快重传这个丢失的报文段。由于只丢失一个报文段，因此不是网络拥塞，于是接下来开始快恢复。
4. 快恢复
令ssthresh=cwnd/2,cwnd=ssthresh，此时直接进入拥塞避免状态。

###### 流量控制（零窗口的含义、接受窗口的协商）
TCP接收方发送的报文中TCP头部有一个滑动窗口字段，用于告知数据发送方自己接受缓存的大小，从而控制发送方的发送窗口，防止因为发送过快而出现数据接收不过来的情况，这叫流量控制，与网络拥塞无关。
如果是零窗口，说明当前接收方的缓存已经满了，不能再接收数据，于是发送方需要暂停发送数据，等待接收方将缓存空出来，然后返回PSH报文告知发送方可以发送了。如果长时间没反应，发送方会发送PSH报文催促接收方尽快将缓冲区的数据交给应用。

###### 对String及其不可变性的理解
* String是被声明为final的，即不可以被继承。Java 8中使用char[]数组来储存数据，Java 9开始改用byte[]储存。
* String的不可变是指一旦给定了一个字符串对象，其中的字符串就不可修改，只能创建新的字符串对象。
* String不可变有4大好处：
  1. 缓存hash值：因为String的hash经常被使用，比如作为HashMap的key来使用，String不可变的话，hash值就仅需计算一次。
  2. String Pool的需要：如果一个String对象已经被创建过了，就能在String Pool中取得引用。只有String不可变，才可能使用String Pool。
  3. 网络安全：在进行信息通信时，参数往往都是以字符串的形式传递。如果字符串可变，很容易就会被篡改，导致信息不一致。
  4. 线程安全：String的不可变性本身就保证了线程安全，可以在多线程间安全地使用。
* String Pool的理解
  * String Pool用于存储字符串字面量，这些字面量在编译期间就确定。在Java 7之前String Pool放在运行时常量池中，属于永久代，但是由于永久代空间有限，在需要大量使用字符串的场景下会出现OOM的问题，因此从Java 7开始移到了堆中。
  * 执行如下语句时，如果String Pool中还没有这个字面量和指向该字面量的String对象，则会生成2个String对象。首先在String Pool中生成一个String对象sp，其value指向字面量"aaa"。然后在堆中生成一个String对象，sp作为参数传入拷贝构造函数。
  ```Java
  String s1 = new String("aaa");
  ```
  最终调用的构造函数如下：
  ```Java
  public String(String original) {
      this.value = original.value;
      this.hash = original.hash;
  }
  ```
  可以看到新对象并没有完全复制字符串，而是指向了同一个value引用。这叫做浅复制。
  * 还可以在运行过程中通过stringObj.intern()方法将字面量加入String Pool中，如果String Pool中查到已经有了这个指向这个字面量的String对象，就会直接返回这个String对象的引用。如果没有，在Java 1.6中会在String Pool中新建一个String对象指向这个字面量，然后返回这个新对象的引用。而在Java 1.7中会在String Pool中加入这个字面量与stringObj的引用，不会再新建实例对象。这种优化的目的主要是为了节省内存。
  >StringDemo及其说明如下
  ```Java
  //编译期间会确定"ab"和"cd"这两个字面量，运行时首先在String Pool中生成这2个字面量和对应的实例对象，然后在toString的时候在堆中生成实例对象ss1，value="abcd"也是在堆中生成，String Pool中不会生成"abcd"的字面量。
  String ss1 = new String("ab") + "cd";//<=> String ss1 = new StringBuilder("a").append("bc").toString();
  //Java 1.6：在String Pool中生成新的实例对象和字面量"abcd"，返回新对象的引用
  //Java 1.7：将堆中实例对象的引用连同字面量加入String Pool，返回ss1对象的引用
  String intern_ss1 = ss1.intern();
  //Java 1.6：false
  //java 1.7：true
  System.out.println(ss1 == intern_ss1);
  //在String Pool中查到了"abcd"字面量及其映射的引用
  //Java 1.6：返回String Pool中的对象的引用
  //Java 1.7：返回堆中ss1的引用
  String ss2 = "abcd";
  //Java 1.6：false
  //Java 1.7：true
  System.out.println(ss1 == ss2);
  //在堆中生成新的实例对象ss3
  String ss3 = new String("a")+"b";
  //由于第1行已经将"ab"加入常量池，因此String Pool中已经有了"ab"对应的实例对象，此时直接返回String Pool中的对象引用
  String intern_ss3 = ss3.intern();
  //均为false
  System.out.println(ss3 == intern_ss3);
  ```
  不用intern的情况(结果上Java 1.6与1.7一致)：
  ```Java
  String ss1 = new String("ab") + "cd";
  //在String Pool中加入字面量"abcd"，并生成新的实例对象指向该字面量，返回新对象的引用
  String ss2 = "abcd";
  //均为false
  System.out.println(ss1 == ss2);
  ```

### 2.29
###### 面向对象的特性
封装、继承、多态。
* 封装就不用多说了。
* 继承是一种类间关系，子类继承父类，意味着子类拥有父类的非私有成员，并且可以重写父类的成员函数。所有抽象类和无显式继承关系的类都默认继承实体类Object，因此可以用Object引用指向所有的对象。
* 多态分为编译时多态和运行时多态。这种多态是通过类对象的方法表实现的。编译后会将调用方法的代码转换成invoke助记符+方法标签的形式，而动态方法的具体入口地址要在运行时从类加载进来的方法表中查找得到（静态方法无需加入方法表，在运行时直接用相对类对象的偏移量替换）。
  * 编译时多态是指在编译期间就确定了要使用的方法是哪一个。比如同一个类中方法的重载，编译期间根据参数就能知道具体要调用哪个方法表中的哪一个方法，在字节码中表现为方法标签的差异，这是静态绑定。
  * 运行时多态是指必须在运行的时候才能知道具体要调用哪一个方法。比如多个子类继承同一个父类，用父类的引用去指向不同的子类对象，并调用重写的非静态方法时，在运行时才能知道要调用的是哪个子类重写的方法，在字节码上表现为方法标签相同，但是运行时会从局部变量表中拿到不同对象的引用，去不同的子类中查找相应的方法表，这叫做动态绑定。这种多态的特性可以使得程序更加简洁统一，在不同情况下要调用不同子类方法，用一个父类引用分时指向不同的子类对象即可，而不用刻意去创建子类的引用，更加灵活。但是有一个弊端就是父类引用不能访问子类独有的成员，因此出现这种需求时仍需要特殊处理。

###### 谈谈你对接口和抽象类的理解
* 抽象类和接口都是不能被实例化的。接口可以看做是抽象类的延伸。
* 抽象类中的成员方法可以实现也可以不实现。成员的访问权限可以是public、protected、private任意一种。抽象类可以被多个子类继承，但是一个子类不能继承多个父类。其继承关系具有严格的类层次要求。
* 接口中的成员都必须是public，字段均默认为static和final的。在Java 8之前，接口中的方法均不能有默认的方法实现。当其他类实现该接口后，必须要实现其中的所有方法，因此如果要对接口进行改动，增加成员方法的话，就要改动实现了该接口的所有类，维护成本较高。从Java 8开始，接口中的方法也可以有默认的方法实现（用default声明），这样就降低了修改接口的成本。接口可以被多个类实现，一个类可以实现多个接口，打破了类继承严格的类层次限制，灵活性更强，再加上Java 8对接口的改进，我们可以说接口优先于抽象类。
* 不过事无绝对，在不同场景下有不同的选择。
  * 3种情况下需要使用抽象类
    1. 相关的类之间需要共享代码时；
    2. 要能控制继承来的成员的访问权限，而不是全为public；
    3. 要继承成员变量是非static和非final的。
  * 2种情况下用接口
    1. 需要让不相关的类实现同样的方法。比如不同的类都可以实现Comparable中的compareTo方法；
    2. 需要多重继承来继承多个类中的方法时，不如直接实现多个接口，简化继承关系。
* 接口可以继承接口，比如List继承了Collection；抽象类可以实现接口；抽象类可以继承实体类，比如所有的抽象类都继承自Object类。

### 2.28
###### 为什么TCP中的初始化序列号要是随机的？
如果初始序列号是固定的，很容易被攻击者猜出后继序列号，并且伪造序列号进行攻击，这已经成为了一种常见的网络攻击手段。鉴于网络安全的问题，初始序列号随机化可以一定程度上减少这种攻击手段成功的概率。

###### 三次握手的时候双方会交换什么数据？
首先是双方发送的TCP报文的序列号(ISN)，其次是自己的端口号，滑动窗口的大小，最大消息长度、是否支持SACK等。

###### 对SACK的理解
* SACK（选择确认）是TCP首部的一个选项，用于对非连续字段进行确认。如果通信双方都支持SACK，则可以在建立连接的时候设置SACK Permitted=true来打开SACK的选项。
* SACK一般由数据接收方生成，且一般是不携带数据的，只有TCP首部。在TCP首部中的选项中可以看到SACK字段，其中left edge表示左边界，right edge表示右边界。假设确认号=x，左边界=x+100，右边界=x+200，表示的是[x,x+100)内的数据还没有收到，而[x+100,x+200)的数据已经收到了，因此发送方仅需重发[x,x+100)的数据即可。
* SACK解决的是普通确认原则下导致的效率问题。以上面的情况为例，在没有SACK的情况下，[x+100,x+200)的数据会放在接收方缓冲区，然后接收方只会返回ackNum=x的ACK包，发送方收到后只会认为x之后的数据都丢失了，于是重传x之后的所有数据，非常浪费时间，极大降低了传输的效率。而SACK就只需重传丢失的那部分数据即可。
* 由于TCP首部的选项最多只能40字节，SACK字段的一对边界就占了8个字节，4对就32个字节，再加上Kind和Length的2个字节，就只剩下6个字节。这意味着SCAK最多只能告知4个以接收到的数据段。

>参考资料：[TCP-IP详解：SACK选项（Selective Acknowledgment）](https://blog.csdn.net/wdscq1234/article/details/52503315)  
[29-tcp可靠传输——选择确认选项（SACK）](https://blog.csdn.net/qq_35733751/article/details/80157509)

### 2.27
###### 聚集索引和非聚集索引
* 聚集索引将表数据都放在索引树上，每一个叶子节点都是一行数据，查找的依据一般都是主键。InnoDB的主键索引就是用聚簇索引实现的。
* 非聚簇索引的叶子节点只存放对应数据的地址，查找的依据可以是主键也可以是非主键索引字段。MyISAM就是使用非聚簇索引，真正的表数据都放在另一块内存空间中。
* 聚集索引的好处就是只需一次查询就能获得自己想要的列数据，而非聚集索引不一定能直接得到自己想要的列，所以可能需要二次查询，效率更低。但是非聚集索引更加轻量，适用于使用非主键索引进行查询的场景。

###### AtomicInteger，原理是什么，如何做到高效率的，有什么优化措施
* AtomicInteger是对int的封装，提供原子性的访问与更新操作，其原子性操作的实现是基于unsafe类的CAS。CAS，即compare and swap(比较和交换)，涉及3个操作数：要更新的内存值V，进行比较的值A，拟写入内存的值B。CAS会先将V与A进行比较，如果相等，就将B赋值给V，如果不等，则开始自旋，进行下一次CAS。
* Java中CAS的底层是调用了C++的本地方法，本地方法再调用CPU指令集，通过基于硬件的原子操作来实现CAS的原子性和高效性。
* AtomicInteger的LongAdder就是一个优化措施，通过分段来降低并发度，将多线程竞争1个资源变成了多线程竞争n个资源，比如使用cell[4]这样的数组。如果要获取数据，就将4个cell数据相加返回，如果要修改数据，就修改自己当前被分配到的cell资源。比如线程A分配到cell[0]，线程B分配到cell[1]。A执行getAndIncrement操作的过程就是将4个cell相加作为返回值，然后将cell[0]进行原子性的加一操作（即CAS）；B执行decrementAndGet操作的过程则是先将cell[1]进行原子性的减一操作（即CAS），然后将4个cell相加并返回。

###### 悲观锁和乐观锁
* 悲观锁假设最坏的情况，总认为自己去拿数据的时候别人会来修改。而乐观锁则是假设最好的情况，每次都不会有其他人来修改数据。
* 悲观锁的典型实现有synchronized和Reentranlock，通过加独占锁的方式使得其他要来修改数据的线程被阻塞。
  * synchronized是一种非公平机制的锁，每次释放锁时，所有锁池中的线程均可竞争锁，虽然不公平，但是保证了高吞吐量。
  * Reentranlock有公平和非公平两种机制，公平就是先到先得，后到排队，非公平就是每个新到的线程都会去尝试拿锁，拿不到了再乖乖排队等候，如果没轮到自己当队头，之后都不能竞争锁，这与synchronized的非公平不太一样。
* 乐观锁的典型实现有版本号机制和CAS算法。
  * 版本号机制会有一个version记录修改次数，每当要更新一个数据时，会同时取出数据和对应的版本号version，更新完数据要写回时，会先检查版本号是否和原来一致，如果一致就将版本号加一，然后同时将版本号和数据刷回去，如果不一致，此次提交就会被驳回。
  * CAS，即compare and swap（比较与交换），先比较后更新，涉及3个操作数：要更新的内存值V，进行比较的值A，拟写入的新值B。如果V==A，就将B赋给V，CAS成功；否则CAS失败。通常与自旋操作搭配使用，失败就取新值继续比较，直至CAS成功为止。
* 下面我讲讲synchronized与CAS的应用场景
  * synchronized一般用于线程冲突严重（资源竞争严重）的场景，如果这种场景下使用CAS的话，大概率会导致线程自旋，白白消耗CPU资源，而用synchronized加锁的话，会直接阻塞线程，避免CPU资源的浪费。
  * CAS一般用于线程冲突较轻（资源竞争较少）的场景，如果这种情况下使用synchronized的话，线程都不会被阻塞太久，此时的线程阻塞唤醒切换、用户态内核态的切换等操作反而会额外消耗CPU资源；而CAS基于硬件实现，不需要进入内核，无需切换线程，同时自旋概率较小，因此性能更高。
>参考资料：[面试必备之乐观锁与悲观锁](https://blog.csdn.net/qq_34337272/article/details/81072874)
[简述乐观锁和悲观锁](https://blog.csdn.net/qq_32600929/article/details/89089577)


### 2.25
###### 垃圾回收机制GC，cms，G1，垃圾回收的算法
常见的垃圾回收器有Serial和Serial Old，ParNew和CMS，以及G1回收器。  
* Serial和Serial Old都是单线程的回收器，前者针对新生代，后者针对老年代。现在Java后端基本不怎么用了。  
* ParNew是针对新生代的支持多线程并发的GC，使用复制算法对新生代垃圾进行回收，将堆内存中的新生代划分为一个Eden区和2个Survivor区，比例一般设置为8:1:1。在运行过程中总会预留一个空闲的Survivor区，举个例子，在某次回收时会将Eden区和S1的存活对象复制到S2区，然后清空Eden区和S1区，接下来只有Eden区和S2区存放对象，直至下一次回收，又将存活对象搬至S1区，清空Eden和S2区，如此往复。  
* CMS是针对老年代的支持多线程并发的垃圾回收器，回收过程要经过初始标记、并发标记、重新标记、并发清理4个步骤。初始标记会让系统线程停止工作，进入Stop the World状态，然后将GC Roots直接引用的对象标记为存活对象；并发标记让系统线程恢复运行，同时进行GC Roots跟踪，将所有GC Roots间接引用的对象都找出来并标记；重新标记又会进入Stop the World，将上一步并发标记过程中发生变化的对象标记出来，包括哪些对象变成垃圾对象，哪些对象是新产生的；并发清理阶段又会让系统线程恢复，然后并发地去清理之前标记出来的所有垃圾对象。由于清理完后，老年代内存空间中的存活对象一般都是东一个西一个，很零散，因此会造成大量内存碎片，JVM有个参数可以设置每几次Old GC进行一次碎片整理。
* G1垃圾回收器也是支持并发线程的，同时负责清理新生代和老年代。并且可以手动控制其垃圾清理对系统性能的影响。
G1将堆内存划分成许多个Region，一般JVM中最多有2048个Region。
G1不明确划分新生代和老年代，而是在运行过程当中进行动态分配和动态转移。
所谓动态分配，举个例子，由于新生代最多占60%的空间，一开始新生代只占2%，然后在不断运行过程中新生代的对象占用会不断增长，直至增长到60%就会触发对新生代的GC。
而动态转移是指，当新生代的某个Region被清空后，这个Region下一次可能就被分配给老年代了。
值得注意的是，在G1机制中，大对象不属于老年代，而是单独分配Region，有可能一个大对象会横跨多个Region。
另外G1的新生代的内存分配依旧是一个Eden区和2个Survivor区，其比例一般也是8:1:1，比如某时刻新生代占了1000个Region，那么其中Eden区占800个Region，Survivor区各占100个，新生代的GC也是使用复制算法，与ParNew类似。
除了新生代触发的垃圾回收，还有老年代触发的混合回收机制。当老年代内存占比超过45%时，就会触发Mixed GC，在这个过程中会同时对新生代、老年代和大对象进行回收。GC过程分为初始标记、并发标记、最终标记、混合回收4个步骤。前三步与CMS的类似，区别在于最后一步。混合回收过程中会计算每个Region中存活对象占比、执行垃圾回收的预期性能与效率，选取部分Region进行回收，保证清理时间不超过预先人为设定的时间。这样就保证了垃圾清理不会对系统性能造成太大的影响。实际上在G1中会记录每个Region的垃圾占用，并据此维护一个优先队列，而清理的具体过程就是从优先队列中弹出部分垃圾占用较高的Region进行回收，另外还有一个规则，如果垃圾占用低于20%就不会去回收这个Region。注意在Mixed GC中的回收也是使用复制算法，将所有Region中的垃圾对象都复制到空闲Region中，然后一次性清理掉原来的Region，这样就避免了内存碎片的问题。

###### TCP连接和释放
* TCP连接建立过程要经过三次握手。假设一个客户端向服务端请求连接，需要经过如下过程：
1. 客户段发送TCP连接请求，即SYN包，其中SYN=1，ACK=0，假设序列号为x，然后客户端进入SYN-SEND状态。
2. 服务端收到SYN包后，确认可以建立连接，就返回一个ACK包，其中ACK=1表示这是一个确认报文，SYN=1表示这同时也是一个连接请求报文。另外，报文中的确认号为x+1，表示希望接收到的下一个报文序号。假设此包序列号为y，然后服务端从LISTEN状态进入SYN-RCVD状态。
3. 客户端收到ACK包后，返回一个对服务端的连接请求的确认报文，进入ESTABLISHED状态。该报文的SYN=0,ACK=1,序号=x+1,确认号=y+1。
4. 服务端接收到ACK报文后，进入ESTABLISHED状态。然后双方开始传输数据。

* TCP连接的释放需要四次挥手。假设客户端已经发送完了所有数据，可以断开连接了，但是服务器还没准备好，此时连接的断开需要经过如下步骤。
1. 客户端发送FIN包，主动请求断开连接，然后进入FIN-WAIT1状态。FIN包中的FIN=1,ACK=0,seqNum=u。
2. 服务端接收到FIN请求后，返回一个ACK，其中FIN=0,ACK=1,seqNum=v,ackNum=u+1，然后进入CLOSE-WAIT状态，此期间会通知应用尽快接收完所有数据。此时TCP连接进入半关闭状态，即只有被动断开连接的一方可以发送数据，另一方只能接收。
3. 服务端准备好后，向客户端发送FIN包请求断开连接，其中FIN=1,ACK=1,seqNum=w,ackNum=u+1，然后进入LAST-ACK状态，等待最后一次确认。
4. 客户端收到FIN包后，返回ACK包表示确认收到断开连接请求，其中FIN=0,ACK=1,seqNum=u+1,ackNum=w+1，然后进入TIME-WAIT状态，等待2MSL后进入CLOSED。
5. 服务端收到ACK后确认可以断开连接了，于是进入CLOSED。
我解释一下在这个过程的最后客户端为什么要等待2MSL再关闭连接。我们知道每个报文在网络中都有一定的生存时间，超过这个时间就会在网络中消失，这个最大报文生存时间叫做MSL。正常情况下报文会在远小于MSL的时间内到达目的地，如果没有到达，说明报文已经不可能到达了，我们此时一般会想要重传。TCP就有这个报文重传机制。当发出去一个需要确认的报文时，如果经过规定的时间T（一般小于2MSL）还没有收到ACK，说明报文有可能丢失了，于是会重新发送这个报文。在第3步服务端发出FIN包后，如果T时间后仍未收到ACK，就会重传这个包，此时客户端要做到就是等到这个重传的包到来，再次发送ACK，保证服务端能够收到ACK并关闭连接，释放端口，避免空等待。如果客户端在2MSL的等待中都没有收到重传的包，大概率是服务端已经收到ACK并正常关闭了，此时客户端便可安心关闭连接了。
>###### 假设说一台电脑上很多端口处于CLOSE_WAIT状态，是发生了什么事呢？
>>说明对应的应用程序出了问题，导致迟迟没有接收数据，因此线程也无法执行CLOSE方法让主机进入LAST-ACK状态。
>###### 如果一台电脑上有很多端口处于TIME-WAIT状态，是发生了什么呢？
>>说明存在很多短连接。


### 2.24
###### String，StringBuffer，StringBuilder区别
* String对象中所包含的是一个不可变字符串序列，一但定义了一个String对象，其中的字符便不可修改。
* StringBuffer对象中操作的是一个可变字符序列的字符缓冲区，实际上就是一个char[]，可通过append、insert、setCharAt等方法来修改字符串，最终通过toString转换成想要的字符串。
* StringBuilder与StringBuffer类似，唯一的不同点在于StringBuffer是线程安全的，而StringBuilder是不安全的。StringBuffer通过对每个方法都加上synchronized关键字的方式进行加锁，从而实现线程安全。但是在并发度较小的情况下建议使用StringBuilder，性能更高。

###### mysql的存储引擎有很多种，你有听过哪些？这些引擎有什么区别呢？
MySQL的存储引擎主要有MyISAM和InnoDB。
1. MyISAM不支持事务，InnoDb支持事务
2. MyISAM不支持行锁，InnoDB支持。
3. MyISAM可以没有主键，使用非聚簇索引；InnoDB必须要有主键，且使用聚簇索引来存储。
4. MyISAM会缓存表中行记录的总数，而InnoDB不会。因为MVCC机制有可能会在不同事务中生成不同的一致性视图，行总数在不同事务中可能是不同的，因此缓存行总数是无意义的。
>其他的区别在版本升级的过程中已经逐步同化了，比如MySQL 5.6之前只有MyISAM支持全文索引，在MySQL 5.6之后InnoDB也开始支持全文索引了。

###### ip头tcp头udp头这些能不能介绍一下？
1. IP头是网络层的东西，固定部分的长度为20字节，其中包含的主要字段有源IP地址、目的IP地址、版本、首部长度、总长度、首部检验和等，我着重介绍一下其中比较有趣的一些字段。
* 标识和片偏移：当数据报过长，超过了一个IP数据报所能容纳的最大长度时，需要进行分片。相同数据报的不同分片具有相同的标识符，片偏移和标识符一起使用，表示当前IP包相对完整数据报首地址的偏移量，片偏移以8个字节为单位。
* 生存时间TTL：这个字段表示可经过的最大路由数，是人为设定的，用于防止不可交付的数据报一直在互联网中兜圈子，以路由器跳数为单位，每经过一个路由器就减一，当TTL减为0时，路由器就会丢弃这个数据报。这字段一般在进行Traceroute的时候使用，用于跟踪从源主机到目的主机的途径的所有路由IP。
* 协议：指出携带的数据要上交给哪个协议去处理，比如ICMP、TCP、UDP。
2. TCP头的固定部分也是20字节，主要字段有源端口、目的端口、序号、确认号、数据偏移、检验和等等，我简要说下其中的部分字段。
* 序号：每个TCP报文都会有一个序列号，用于标识当前TCP报文数据部分的第1个字节在本次TCP连接中的编号，加入当前序号为200，数据部分长度为1字节，那么下一个TCP报文的序号就是201。
* 确认号：当标志ACK为1时有效，表示这是一个确认报文，确认号是期望收到的下一个TCP报文的序号。一般只会对携带数据的、携带SYN的、携带FIN的TCP报文进行确认。
* 数据偏移表示数据部分相对于TCP首地址的偏移量。
* 窗口：是接收方用于告知发送方设置发送窗口的依据，因为接收方的接收缓存有限，发送方需要控制一次性发送的字节数。
* 紧急指针：当URG标志为1时，该字段有效，此时该报文中的数据部分会分为紧急数据和普通数据，紧急指针指向的是紧急数据的最后一个字节，之后的便是普通数据。当主机收到这样的TCP报文，会优先处理其中的紧急数据，尽管它们还没有进入滑动窗口。
* 标志：RST、SYN、ACK、FIN、PSH、URG共6个标志位，每个标志位占用1个bit，其中SYN、ACK、FIN都比较常见，URG在前面紧急指针的介绍中提过，剩下的RST是连接复位标志，收到此包的进程会将回滚到建立TCP连接前的状态。而PSH是用于催促发送方赶紧把缓冲区的数据发送出来或者催促接收方赶紧把缓冲区的数据交给应用。
3. UCP头比较简单，只有8个字节，包括的字段有源端口、目的端口、长度、检验和。除此之外还有一个12字节的伪首部，里面主要是源IP、目的IP、UDP长度这些信息，是用于计算检验和而临时添加的。

### 2.23
###### 进程如何同步
1. 信号量  
信号量本质就是一个整型变量，通过P和V操作来控制同步进程对临界区的访问。所谓临界区，就是一段对临界资源进行访问的代码。  
P、V操作都是原子性的操作，通过在运行期间屏蔽中断的方式来实现原子性。P将信号量s的值减一，V则将s加一。s的初始值表示能同时进入临界区的进程数目。如果s为非正数，P操作将其减一后会将调用P方法的进程加入阻塞队列。V则从阻塞队列中释放出一个进程。

2. 管程  
一般用于解决生产者消费者问题，相比信号量，省去了很多控制代码。管程的特点是只能有一个进程进入管程，其他进程都将被阻塞。管程通过使用2个条件变量full和empty的wait()和signal()操作来控制生产者和消费者的行为，避免向满缓冲区中插入东西或者消费空缓冲区。

3. 消息队列  
消息队列实际上是以一对原语来实现其功能，分别是send和receive，指明接收方和发送方以及要传递的消息。这样当一个进程执行完一段互斥代码后就可以调用send操作通知指定的被receive阻塞的进程去执行这段代码。

###### 谈谈你对TCP中确认原则的理解
TCP最大的特点就是确认原则，解决的是能不能通信的问题。  
有3种报文收到后需要确认：携带数据的、携带SYN的、携带FIN的TCP报文。  
有2种报文是无需确认的：不携带数据的ACK报文、携带RST的报文。  
另外，TCP进行确认的时机也是很有讲究的。由于返回ACK报文也要消耗一部分CPU资源，因此每次都返回ACK的话，开销会增大，CPU处理TCP报文的时间会变长。因此现在一般都是每收到2个报文再返回对后面这个报文的ACK，这叫做*延迟确认**（Delayed ACK）。但是如果第一个报文发来很久都没有收到第二个报文，此时会有一个Delayed ACK定时器（Timer）进行检测，一旦超时，就会赶紧将ACK发出。

###### TCP/IP层的一些专用概念
RTT：报文往返时间。  
RTO(Retransmission Timeout)：最大报文超时重传时间。  
MSL(Maximun Segment Lifetime)：最大报文段寿命，与TTL有关，但MSL更大。  
TTL(Time To Live)：IP数据报可经过的最大路由数。是IP层的概念。

###### TCP头部是怎样的
TCP头部有20个固定字节，里面包含了目的和源端口号，序号、确认号、数据偏移、窗口、检验和、紧急指针、RST、PSH、URG、SYN、FIN、ACK等字段。
* 序号是当前TCP报文中的数据部分的第1个字节在整个字节流中的编号（即第几个字节）。  
* 确认号是期望收到的下一个TCP报文的序列号。  
数据偏移是该TCP报文中数据部分的首地址相对于TCP报文首部的偏移量。  
* 窗口值是接收方让发送方设置其发送窗口的依据，用于告知发送方一次性最多发送几个字节，因为接收方的接收缓存有限，这就是TCP的流量控制。
* 紧急指针：当URG字段为1时有效，指向的是紧急数据的最后一个字节，之后的都是普通数据。
* RST是连接复位字段，让接收到此包的进程回滚到建立TCP连接前的状态。
* PSH字段用于催促接收方尽快将缓冲区的数据交给应用或者催促发送方尽快将缓冲区的数据发送出来。
* URG是紧急字段，用于声明这是一个包含紧急数据的TCP报文，与紧急指针配合使用。
* SYN是同步字段，表明当前正在建立TCP连接。SYN=1,ACK=0时表明这是一个连接请求报文。
* ACK是确认字段，为1时表明这是一个确认包，确认已经收到了对方发来的TCP报文，与确认号配合使用。
* FIN是结束字段，为1时表明要请求关闭连接。

###### TCP的头部除了SYN、ACK外，还有哪些标记位？它们都有哪些作用
* RST(连接复位)字段  
RST为1时，接收到RST包的一方将回退到建立TCP连接之前的状态。
1. SYN被发给了一个不处于listen状态的端口。
>此时OS发现监听这个端口的进程尚未处于listen状态，于是返回一个RST包。
2. 发送的SYN超时后又收到了ACK。
>此时OS拆开ACK包，发现本机上对应端口的进程已经关闭连接，于是返回一个RST包。
3. 宕机重启后收到了上一次TCP连接中传过来的信息。
>此时该TCP连接处于半开启状态，即一方意外中断，另一方仍然保持连接。OS发现找不到对应的进程来处理这些信息，就当是对方发错了，于是返回一个RST包。
4. 国家防火墙监控流量时发现有进程尝试进行非法连接。
>此时防火墙会伪造RST包发给正在建立连接的两台主机。

* PSH字段  
1. 当数据接收方发PSH给发送方时，意在催促发送方赶紧把包发过来，不要老放在缓冲区里。  
2. 当数据发送方发PSH给接收方时，旨在催促接收方赶紧把数据交给应用层，不要老放在缓冲区。

* URG字段  
URG字段表明一个报文是否是紧急（urgent）报文。  
URG为1时，紧急指针有效，指向的是紧急数据的最后一个字节，该字节之后的数据都是普通数据。  
接收方收到这个TCP报文后放在缓冲区中，即使没有进入滑动窗口（或者窗口大小为0），也会预先处理这个TCP报文中的紧急数据。

### 2.22
###### HTTPS加密了什么内容
HTTPS就是加了一层TLS的HTTP。而TLS是属于会话层的协议，介于应用层和传输层之间，TLS和HTTP协议共同为用户提供安全的访问网页的服务。  
HTTPS实际加密的只有HTTP头和内容，数据的发送方和接收方在建立TLS安全连接的时候交换的对称秘钥可以解开，任何没有秘钥的第三方都无法获取其中的明文，但是仍然可以获取TLS、端口、IP等的内容。

###### 邮件传输安全吗？
用户登录时通过HTTPS交换了相关的Session ID、Access Token、对称秘钥等私密信息。发送方使用SMTP协议进行邮件的安全发送，使用TLS对邮件内容加密后发送给服务器。服务器使用POP3/IMAP安全接收邮件，使用TLS解密获取明文。
但是邮件传输有一个致命的弱点，如果建立TLS连接总是失败，那么就会退而求其次，直接明文传输。HK就可以利用这一缺陷，从中作梗，人为的让双方连接过程中不停丢包，失败了一定次数后就会使用明文传输，这样HK就可以窃取邮件内容。所以并不安全。

###### 网关、路由器、三层交换机之间的区别在哪？
* 网关只是一个抽象概念，具体可以通过路由器、三层交换机、三层防火墙来实现，它们都是三层接力设备，可以处理IP报文头，主要用于转发跨网段的数据包。
* 路由器和三层交换机都是用来连接不同的网段，做一些数据包转发的工作。不同点在于硬件架构不同，三层交换机优化转发效率，而路由器的接口更丰富。

>* 网桥：二层交换机，是二层接力设备，也可以完成信号的转发，但是只能处理二层的以太帧头。
* 集线器/信号放大器：是一层接力设备，也能转发信号，但是只能处理物理信号，无法理解信号内容。

###### 进程间通信有哪些方法？
1. pipe：匿名管道，只能用于父进程与子进程之间的半双工通信。
2. FIFO：命名管道，可用于同一主机内任意两个进程间的通信，常用于客户-服务端应用程序中，FIFO作为汇聚点，在客户端进程和服务端进程之间传递数据。FIFO同步管道由读写进程创建，通过fd来访问同一个管道，从而实现进程间通信。这个管道随着读写进程的关闭而销毁。
3. 消息队列：不同于FIFO，消息队列进程独立于读写进程。
>~~（面试不用说）消息队列具有以下优点：
(1)消息队列独立于读写进程，由消息队列这个进程来负责统一管理，避免了FIFO的同步打开与关闭困难（如多进程打开文件时的重名问题，此时其他同步进程将出现报文件打开失败的错误）。
(2)读写进程仅需调用消息队列的API进行读写操作，不用自己提供同步方法，避免了FIFO的同步阻塞问题。
(3)消息队列中可以存放很多个打开的fd，读进程可以根据需要读取特定类型的消息。但是FIFO只能存放一个fd，读进程一股脑的读一堆进来，然后再将不需要的舍弃。~~
4. 信号量：就是一个计数器，用于同步多个进程对共享数据对象的访问。
5. 共享存储：多个进程共享同一块内存。具体来说是将这块内存映射到进程内的地址空间中，不用在内核空间中创建该存储块的fd，直接通过用户空间中的逻辑地址就能访问到同一个存储块的物理空间。这种方式需要使用信号量来同步对共享存储的访问，仅适用于要共享大块数据时。
6. Socket：用于跨主机或跨LAN的进程间通信。

>参考资料：
* [目前linux进程间通信的常用方法是什么(pipe？信号量？消息队列？)?](https://www.zhihu.com/question/23995948)
* [进程间通信-管道](https://zhuanlan.zhihu.com/p/106222551)
* [semaphore和mutex的区别？](https://www.zhihu.com/question/47704079)

### 2.21
###### 谈谈你对线程池的理解
线程池的思想有点类似于IoC，也是控制反转。将手动创建线程变成了由机器自动创建线程，根据系统情况调整线程数目，降低了内存的消耗，并减少了创建和销毁线程的次数，每个工作线程可被重复利用。

###### 浏览器输入完url按下回车开始到返回页面的过程
假设使用的是HTTP协议。
1. 浏览器先查询本地host，如果没有匹配的URL，就向DNS服务器发送查询请求，本地域名服务器向根域名服务器查询一般使用迭代查询。浏览器收到正常回复后即拿到对应的IP地址。
2. 浏览器生成一个HTTP请求报文，交由OS的传输层，将这份HTTP请求拆分成字节流，套上TCP头，交给网络层。
3. 网络层对收到的TCP数据流进行分组，生成IP包，交给链路层。
4. 如果IP属于外网，会将MAC地址设置成路由器的MAC；如果是内网IP，就查询本地ARP缓存，如果没有记录，就向路由器发送ARP请求，取得对应机器的MAC地址。这里假设IP属于外网。
5. 链路层给IP包套上MAC头，然后将生成的MAC帧交给物理层。
6. OS将完整的帧发送出去，路由器收到后，根据IP层的目标IP地址，加上下一跳的MAC地址，进行相应的转发。
7. 经过若干次转发后，到达目标局域网的路由器（即最后一跳）。路由器取下IP头，发现这个包是发给自己管辖的局域网内的主机，没有下一跳了，于是进行ARP，获得目标主机的MAC地址后，发送到自己的局域网下。
8. 目标主机收到了这个包，接收过程是发送过程的逆过程，最终这个HTTP请求报文会被交给监听对应端口的进程去处理。
9. 进程处理好后，会生成一个HTTP响应报文，经过同样的过程，层层封装好后发给我们的浏览器。
10. 浏览器收到HTTP响应报文后，取出其中的html内容，然后就可以展示这个完整的网页了。
[Linux系统下搭建DNS服务器——DNS原理总结](https://zhuanlan.zhihu.com/p/31568450)

### 2.20
###### 什么叫做JIT compiling，与传统的编译技术有何不同。
JIT，Just-In-Time，是即时的意思，即时编译器也叫做热点编译器，是一种动态编译器。

不同于C/C++的静态编译，JIT compiler是运行时编译（Runtime Compilation），一般应用于Java虚拟机中。Java解释器会将热点代码（即频繁被执行的字节码）交由JIT，JIT将其编译成本地（机器）代码，之后要执行的时候Java解释器便可直接调用，避免再次编译。

JIT compiler的作用对象是中间产物.class字节码文件中的热点代码，生成的是与本地平台适配的机器码。而字节码文件是由javac程序编译.java源代码文件得到的。

传统的编译技术是在程序运行之前进行全局编译，编译的对象是整个源代码，编译的产物就是可以直接执行的机器码。

###### HashMap，为什么使用红黑树
相比于链表，红黑树可以将插入和查询时间复杂度降到O(logN)，而链表的插入和查询都需要遍历整个链表，复杂度均为O(N)，当数据量极大时，效率将十分低下。不过在数据量较小的情况下还去维护一棵复杂的红黑树反而有点小题大做，因此在HashMap中设置了一个树化和链表化的阈值，数据个数大于前者，就将链表转换成红黑树，数据量小于后者，就简化成一条链表。
相比于二叉搜索树，红黑树可以在插入时自动调整左右子树的高度，防止左右高度相差太大导致查询效率降低。
相比于二叉平衡树，红黑树的平衡条件没这么苛刻，插入时所做的调整没这么频繁，效率更高，但是也不会太过降低查询效率，相当于在普通二叉搜索树和平衡树之间做了一个折中。

###### synchronized
每个对象都有一个Monitor数据结构，这个数据结构中又包含了锁池和等待池这两个数据结构。synchronized关键字用来修饰一个方法或者一个代码块，表示这段代码是临界区，同一时刻只能有一个线程进入临界区执行。具体实现是利用一个对象的Monitor，只有第一个拿到Monitor的线程才能进入临界区，其他线程将被阻塞在这个对象的锁池中，直至Monitor被释放，锁池中的线程才会被唤醒来竞争这个Monitor，拿到Monitor的线程将从锁池中移除，进入临界区，其他竞争失败的线程依旧留在锁池中等待下一次被唤醒。

### 2.19
###### java的基本数据类型和字节数
byte:1
char:2
short:2
int:4
float:4
long:8
double:8
boolean:?
>boolean可以用1bit来存储，但是没有明确规定其大小，JVM在编译时会将boolean型数据转换成int型，boolean数组则是当做byte数组处理。

###### Java，volatile关键字
volatile是指令关键字，用于修饰指令，主要有以下两大特性：
1. 可见性：保证每个线程都能看到最新的共享变量值。大致的实现方式如下：
假设有多个线程已经加载了共享变量val的副本到各自的工作内存中，此时线程A对val的值进行了更新并写入主内存，那么其他线程的工作内存中加载的val副本就会失效。当其他线程要用到val时，会发现工作内存中存放val副本的地址已经失效，就会重新去主内存中加载val的值进来。
2. 有序性：通过内存屏障（也叫栅栏）来防止编译器优化volatile声明的指令进行顺序重排。

###### mysql索引结构，特点，为什么使用这个
索引可以使用二叉搜索树、哈希表、B-树、B+树来实现。
1. MySQL采用B+树作为索引结构。
2. B+树的特点是树高比二叉搜索树低，这样查询数据时需要访问的层数可大大减少。
3. 原因：
* 与二叉搜索树相比，由于B+树是n叉搜索树，在同样数据量的情况下，B+树的高度不会过高。一般而言，索引的一个结点中的所有数据会存放在同一个扇区内，因此对索引每一层的访问都对应一次磁盘I/O，其时间主要分为2块，磁头移动寻找磁道的时间和磁盘转动寻找扇区的时间。故磁盘I/O的时间比内存I/O要长很多。因此减少磁盘访问次数就成为了提高数据库查询效率的关键点。
* 与哈希表相比，B+树支持范围查询，而哈希表不支持。
* 与B-树相比，B+树的非叶子节点不存储真实数据，而只会存放辅助查找的值，而B-树的真实数据分布在不同的层上，要进行范围遍历时会比较麻烦。B+树只要直接将所有叶子节点用双向链表进行组织，就可进行范围查询，非常方便。

>* 二叉平衡树：左右子树的最大深度之差不能超过1
* 红黑树：本质也是一棵二叉搜索树，规则是左右子树中更深的那棵子树的长度不能大于另一棵的两倍

###### ReentrantLock
* 重入锁，顾名思义，就是已经拿到锁的线程可以重复拿锁。
* ReentrantLock分为公平锁和非公平锁。
* 它们的区别在于当有新的线程想要拿锁的时候，公平锁只会让第一个线程去做拿锁的尝试，而后面的线程只能进入队列中等待；但是非公平锁会让每一个新来的线程都去进行拿锁的尝试，一旦锁刚好被释放，就有一定概率比队头的线程先拿到锁，就不用再排队，违反先来后到的公平机制，故是非公平的锁。

###### JMM
Java内存模型：将内存条划分为主内存和多个工作内存，每个线程都拥有一个工作内存。主内存用于存放共享变量，工作内存存放共享变量副本，线程不能直接操作主内存中的共享变量，需要将主存中的共享变量加载到工作内存才能够操作。
>不能与JVM内存分区混为一谈。JVM内存分区是物理上的划分，而JMM是逻辑上的划分。

### 2.18
###### 文件IO
每个文件file都有一个文件描述符fd，fd这个对象主要是用来指向文件所在地址。
当执行read操作时，会产生系统调用，内核会通过fd，从磁盘上文件的对应位置，以扇区(block)为单位，即4KB为单位加载进内核空间的页框（也是4KB）中，再从内核空间读取到用户空间的页框中，即完成一次读取（载入）操作。
当执行write操作时，也会产生一个系统调用，将指定的用户空间的n个内存页的内容写入内核空间的缓冲区，再写入磁盘的n个扇区。

### 2.17
###### 进程和线程，区别，哪个效率高，为什么
1. 定义：进程是资源分配的基本单位。线程是处理器调度的基本单位。
2. 区别：一个进程可拥有多个线程。每个进程都拥有自己独立的地址空间，而同一个进程内的线程共享该进程的地址空间。
3. 效率高低比较：
多进程并发与多线程并发没有绝对的效率高低，要视情况而定。  
如果是不同进程的线程切换，则与进程切换无异。  
如果是同一进程内的线程切换，则其成本和效率比进程切换效率更高。进程切换时，需要MMU进行缓存的刷新，即先清除前一个进程的缓存再加载后一个进程的缓存。但是进程内的线程切换无需进行如此大规模的MMU缓存刷新操作，开销较小。

###### 事务的特性，具体介绍
ACID
* 原子性：事务中的步骤要么不做，要么全做。
* 一致性：(选其一回答)
>抽象解释：事务执行的结果应该是使数据库从一种一致性状态变为另一种一致性状态。即哪怕事务被意外中断，其所做的修改不会更新到物理数据库上，即为一致性。
>举例解释：举个转账的例子，A转账给B一百块钱，要执行两步操作，首先从A的账户余额中扣除100，然后给B的账户余额增加100。这个转账操作必须是一个原子性的操作，否则，如果执行了第一步余额扣除操作，并同步到物理数据库上，此时事务突然被意外中断，第二步操作没有执行，那么A和B的总资产就变少了，此时就不是一致性状态了。

* 隔离性：并发执行多个事务，互不干扰。
* 持续性：事务一旦提交，其对数据库的改变就是永久性的。

###### 隔离级别，具体介绍
读未提交：所有事务可以看到其他未提交事务的执行结果。读未提交的数据，称为脏读。
读提交：所有事务只可以看到其他已提交事务的执行结果。
可重复读：在一次事务执行期间读到的数据都是一致的。
串行化：后来的事务必须等待前一个事务执行完毕才能开始执行。

###### 幻读
在不同时刻读到不同的数据的现象，就是幻读。
在MySQL中，通过将库的引擎设置为支持事务的引擎，如InnoDB，使用可重复读的隔离级别即可解决幻读问题。可重复读是通过在事务开始执行时生成一份一致性视图，即静态视图来实现的，在事务执行期间一直使用这份视图进行读操作，这样无论在什么时刻读都不会读到前后不一致的值。

###### 死锁的条件，如何解决
死锁是多个并发进程因争夺系统资源而产生相互等待的状态。  
死锁有4个必要条件：
1. 互斥：不能有2个以上的进程同时占有同一份资源。
2. 占有且等待：一个进程在等待另一个进程释放其所需的资源。
3. 不可抢占：一个进程不可强行将另一个进程已经占有的资源抢过来。
4. 循环等待：存在一个进程链，每个进程所需的部分资源被后一个进程所占有。

解决方案  
1. 死锁预防：破坏4个必要条件之一。比如破坏“占有且等待”，就可以在进程开始运行前就一次性为其分配好所有需要的资源。
2. 死锁避免：在进程运行前进行判断，只允许不会产生死锁的进程申请资源。比如银行家算法，通过提前模拟一个进程的运行过程来判断是否会导致死锁。
